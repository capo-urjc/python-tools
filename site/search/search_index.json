{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to capo-tools documentation","text":"<p>Here will be the documentation for the capo-tools package.  This is a work in progress and, though the functions included may be working and useful,  the library itself is highly experimental and may change in the future so not recommended for production use. Use at your own risk.</p> <p>To test the library you can install it from test pypi using the following command:</p> <pre><code>pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple --upgrade capo_tools\n</code></pre>"},{"location":"#bienvenido-a-la-documentacion-de-python-tools","title":"Bienvenido a la Documentaci\u00f3n de python-tools","text":"<p>Este proyecto realizado por capo-urjc es una herramienta escrita en Python que hace ...  Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo usar, configurar y desarrollar la herramienta.</p>"},{"location":"#contenido","title":"Contenido","text":"<ul> <li>Introducci\u00f3n</li> <li>Instalaci\u00f3n</li> <li>Referencias de la API</li> </ul>"},{"location":"#introduccion","title":"Introducci\u00f3n","text":"<p>breve descripci\u00f3n del proyecto, sus objetivos y c\u00f3mo puede ayudar a los usuarios.</p>"},{"location":"#instalacion","title":"Instalaci\u00f3n","text":"<p>Para instalar el proyecto, puedes usar:</p> <p>```bash pip install ...</p>"},{"location":"acciones_explicadas/","title":"Acciones explicadas","text":"<p>Este manual describe el funcionamiento de las tres acciones automatizadas disponibles en este proyecto. Cada acci\u00f3n est\u00e1 dise\u00f1ada para facilitar tareas clave como la gesti\u00f3n de dependencias, generaci\u00f3n de documentaci\u00f3n y despliegue de paquetes.</p> <p>Python package</p>"},{"location":"acciones_explicadas/#1-instalar-dependencias-ejecutar-linting-y-tests","title":"1. Instalar dependencias, ejecutar linting y tests","text":""},{"location":"acciones_explicadas/#descripcion","title":"Descripci\u00f3n","text":"<p>Esta acci\u00f3n instala las dependencias del proyecto, ejecuta an\u00e1lisis de c\u00f3digo con <code>flake8</code> y realiza los tests definidos en el proyecto. Se activa en los siguientes casos: - Cuando se hace un push a cualquier rama. - Cuando se crea un pull request a <code>main</code>.</p>"},{"location":"acciones_explicadas/#proceso","title":"Proceso","text":"<ol> <li>Instala todas las dependencias necesarias definidas en los archivos del proyecto.</li> <li>Ejecuta <code>flake8</code> para asegurarse de que el c\u00f3digo cumple con las normas de estilo y calidad.</li> <li>Corre los tests definidos, asegur\u00e1ndose de que el proyecto es funcional y no contiene errores.</li> </ol>"},{"location":"acciones_explicadas/#activacion","title":"Activaci\u00f3n","text":"<ul> <li>Trigger: Push a cualquier rama o Pull Request.</li> </ul> <p>Generate and Publish Documentation</p>"},{"location":"acciones_explicadas/#2-generar-documentacion-automaticamente","title":"2. Generar documentaci\u00f3n autom\u00e1ticamente","text":""},{"location":"acciones_explicadas/#descripcion_1","title":"Descripci\u00f3n","text":"<p>Esta acci\u00f3n genera la documentaci\u00f3n del proyecto combinando: - Los docstrings de los archivos ubicados en <code>src/</code>. - Cualquier documentaci\u00f3n adicional definida manualmente en los archivos de la carpeta <code>docs/</code>.</p> <p>El resultado es un sitio de documentaci\u00f3n actualizado autom\u00e1ticamente.</p>"},{"location":"acciones_explicadas/#proceso_1","title":"Proceso","text":"<ol> <li>Escanea los archivos en <code>src/</code> y procesa los docstrings.</li> <li>Incluye la documentaci\u00f3n manual definida en <code>docs/</code>.</li> <li>Genera un sitio est\u00e1tico que puede ser desplegado para consulta.</li> </ol>"},{"location":"acciones_explicadas/#activacion_1","title":"Activaci\u00f3n","text":"<ul> <li>Trigger: Push a <code>main</code> o de forma manual en la pesta\u00f1a <code>Actions</code> de Github.</li> </ul> <p>Upload Python Package</p>"},{"location":"acciones_explicadas/#3-crear-y-publicar-paquete-en-test-pypi","title":"3. Crear y publicar paquete en Test PyPI","text":""},{"location":"acciones_explicadas/#descripcion_2","title":"Descripci\u00f3n","text":"<p>Esta acci\u00f3n automatiza la creaci\u00f3n y despliegue de un paquete Python en Test PyPI. El paquete incluye la etiqueta asociada al nombre del release publicado.</p>"},{"location":"acciones_explicadas/#proceso_2","title":"Proceso","text":"<ol> <li>Instala las dependencias necesarias para empaquetar el proyecto.</li> <li>Crea el paquete del proyecto usando herramientas como <code>setuptools</code> o <code>pdm</code>.</li> <li>Publica el paquete en Test PyPI con el nombre y la versi\u00f3n obtenidos del release.</li> </ol>"},{"location":"acciones_explicadas/#activacion_2","title":"Activaci\u00f3n","text":"<ul> <li>Trigger: Publicaci\u00f3n de un release.</li> </ul>"},{"location":"acciones_explicadas/#notas","title":"Notas","text":"<ul> <li>El nombre del release se utiliza como etiqueta del paquete en Test PyPI.</li> <li>Aseg\u00farate de que las credenciales para Test PyPI est\u00e1n configuradas en los secrets del repositorio.</li> </ul>"},{"location":"acciones_explicadas/#preguntas-frecuentes-faq","title":"Preguntas Frecuentes (FAQ)","text":""},{"location":"acciones_explicadas/#que-sucede-si-una-accion-falla","title":"\u00bfQu\u00e9 sucede si una acci\u00f3n falla?","text":"<p>Si alguna acci\u00f3n falla, revisa los logs generados en GitHub Actions para identificar el problema. Los errores comunes incluyen: - Dependencias faltantes. - Estilo de c\u00f3digo incorrecto (flake8). - Tests fallidos.</p>"},{"location":"acciones_explicadas/#como-puedo-personalizar-estas-acciones","title":"\u00bfC\u00f3mo puedo personalizar estas acciones?","text":"<p>Edita el archivo <code>workflow.yml</code> correspondiente en el directorio <code>.github/workflows/</code>. Aseg\u00farate de seguir las normas de sintaxis de YAML.</p>"},{"location":"acciones_explicadas/#donde-puedo-ver-la-documentacion-generada","title":"\u00bfD\u00f3nde puedo ver la documentaci\u00f3n generada?","text":"<p>La documentaci\u00f3n generada se encuentra en la carpeta <code>site/</code>, que puede ser desplegada en GitHub Pages o cualquier servidor est\u00e1tico.</p> <p>\u00a1Gracias por usar estas acciones automatizadas! Si necesitas m\u00e1s ayuda, no dudes en consultar con el equipo o revisar la configuraci\u00f3n de los workflows.</p>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#capo_tools.datasets.CAVE.dataset","title":"dataset","text":"<p>Classes:</p> <ul> <li> <code>CAVEDataset</code>           \u2013            <p>Dataset class for loading Hyperspectral images dataset (CAVE).</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset","title":"CAVEDataset","text":"<pre><code>CAVEDataset(root_dir: str, patch_size: tuple, transform=None, download=False, mode='train')\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Dataset class for loading Hyperspectral images dataset (CAVE).</p> <p>Parameters:</p> <ul> <li> <code>root_dir</code>               (<code>str</code>)           \u2013            <p>Root directory where the dataset is stored.</p> </li> <li> <code>patch_size</code>               (<code>tuple</code>)           \u2013            <p>Size of the patch to be extracted from the images.</p> </li> <li> <code>transform</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Optional transform to be applied on the samples.</p> </li> <li> <code>download</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, downloads the dataset from the internet if it's not already downloaded.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'train'</code> )           \u2013            <p>Mode of the dataset ('train', 'valid', 'test'.).</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.tools","title":"tools","text":""},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling","title":"downsampling","text":"<p>Classes:</p> <ul> <li> <code>DownSampling_LossChannels</code>           \u2013            <p>Crop the given image at a random location.</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels","title":"DownSampling_LossChannels","text":"<pre><code>DownSampling_LossChannels(loss_ch=None)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Crop the given image at a random location.</p> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Args:</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels.forward","title":"forward","text":"<pre><code>forward(y)\n</code></pre> <p>Parameters:</p> <ul> <li> <code>y</code>               (<code>Tensor</code>)           \u2013            <p>Image to be downsampled channel-wise. [ch, height, width]</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y}</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.utils.extract_random_patch","title":"extract_random_patch","text":"<p>Functions:</p> <ul> <li> <code>extract_random_patch</code>             \u2013              <p>Extracts a random patch of size 'size' from the input image.</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.CAVE.utils.extract_random_patch.extract_random_patch","title":"extract_random_patch","text":"<pre><code>extract_random_patch(image, size)\n</code></pre> <p>Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries.</p> <p>Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch.</p> <p>Returns: - patch: NumPy array representing the extracted patch.</p>"},{"location":"api/#capo_tools.datasets.ETS2.dataset","title":"dataset","text":"<p>Classes:</p> <ul> <li> <code>ETS2Dataset</code>           \u2013            <p>Pytorch Dataset for ETS2 dataset, single frame</p> </li> <li> <code>ETS2DatasetVideo</code>           \u2013            <p>Pytorch Dataset for ETS2 dataset, video sequence</p> </li> <li> <code>ToTensor</code>           \u2013            <p>Convert ETS2 sample to Tensors</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset","title":"ETS2Dataset","text":"<pre><code>ETS2Dataset(data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None)\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Pytorch Dataset for ETS2 dataset, single frame</p> <p>The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30</p> <p>Attributes:</p> <ul> <li> <code>data_path</code>               (<code>str</code>)           \u2013            <p>Path to the dataset</p> </li> <li> <code>is_train</code>               (<code>bool</code>)           \u2013            <p>Whether the dataset is for training or not</p> </li> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>Telemetry data</p> </li> <li> <code>indexes</code>               (<code>list</code>)           \u2013            <p>List of indexes to use from the dataset</p> </li> <li> <code>transform</code>               (<code>callable</code>)           \u2013            <p>Optional transform to be applied to the sample</p> </li> </ul>"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2DatasetVideo","title":"ETS2DatasetVideo","text":"<pre><code>ETS2DatasetVideo(indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0)\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Pytorch Dataset for ETS2 dataset, video sequence</p> <p>The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30</p>"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ToTensor","title":"ToTensor","text":"<p>               Bases: <code>object</code></p> <p>Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors</p>"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file","title":"depth_file","text":"<p>Classes:</p> <ul> <li> <code>ETS2DepthFile</code>           \u2013            </li> <li> <code>ETS2DepthFileHeader</code>           \u2013            </li> </ul>"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile","title":"ETS2DepthFile","text":"<pre><code>ETS2DepthFile(file: str, far_value: float = 10000, eager_load: bool = True)\n</code></pre> <pre><code>file ():\nfar_value ():\neager_load ():\n</code></pre>"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader","title":"ETS2DepthFileHeader","text":"<pre><code>ETS2DepthFileHeader(data)\n</code></pre> <pre><code>data ():\n</code></pre>"},{"location":"api/#capo_tools.display.tools.depth_tools","title":"depth_tools","text":"<p>Functions:</p> <ul> <li> <code>colorize</code>             \u2013              <p>Colorize the data using the specified colormap</p> </li> <li> <code>normalize</code>             \u2013              <p>Normalize the data to the range [0, 1]</p> </li> </ul>"},{"location":"api/#capo_tools.display.tools.depth_tools.colorize","title":"colorize","text":"<pre><code>colorize(data, colormap_name='magma', normalize_data=True, invert=False)\n</code></pre> <p>Colorize the data using the specified colormap</p>"},{"location":"api/#capo_tools.display.tools.depth_tools.normalize","title":"normalize","text":"<pre><code>normalize(data)\n</code></pre> <p>Normalize the data to the range [0, 1]</p>"},{"location":"api/#capo_tools.pt_functions.ffts","title":"ffts","text":"<p>Functions:</p> <ul> <li> <code>ffp3d</code>             \u2013              <p>Perform 3D Fast Fourier Transform and Convolution in the frequency domain.</p> </li> <li> <code>psf2otf3d</code>             \u2013              <p>Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain.</p> </li> </ul>"},{"location":"api/#capo_tools.pt_functions.ffts.ffp3d","title":"ffp3d","text":"<pre><code>ffp3d(tensor, kernel)\n</code></pre> <p>Perform 3D Fast Fourier Transform and Convolution in the frequency domain.</p> <p>Parameters:</p> <ul> <li> <code>tensor</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>kernel</code>               (<code>Tensor</code>)           \u2013            <p>Convolution kernel.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>torch.Tensor: Convolved tensor.</p> </li> </ul>"},{"location":"api/#capo_tools.pt_functions.ffts.psf2otf3d","title":"psf2otf3d","text":"<pre><code>psf2otf3d(kernel, input_shape, n=1)\n</code></pre> <p>Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain.</p> <p>Parameters:</p> <ul> <li> <code>kernel</code>               (<code>Tensor</code>)           \u2013            <p>The PSF kernel.</p> </li> <li> <code>input_shape</code>               (<code>tuple</code>)           \u2013            <p>Shape of the input tensor (channels, height, width).</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of samples. Defaults to 1.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>torch.Tensor: OTF of the kernel.</p> </li> </ul>"},{"location":"manual_de_usuario/","title":"Manual de Usuario: Uso de Acciones de Automatizaci\u00f3n en el Proyecto","text":"<p>Este manual est\u00e1 dise\u00f1ado para guiar a los desarrolladores en el uso de las acciones de automatizaci\u00f3n configuradas en el proyecto. Aqu\u00ed se explica qu\u00e9 hacer para a\u00f1adir funcionalidades al proyecto, gestionar nuevas librer\u00edas y activar los workflows correctamente.</p>"},{"location":"manual_de_usuario/#1-acciones-automatizadas-en-github-actions","title":"1. Acciones Automatizadas en GitHub Actions","text":"<p>El proyecto cuenta con tres acciones automatizadas para garantizar la calidad, la documentaci\u00f3n y el empaquetado del proyecto. Estas acciones est\u00e1n explicadas m\u00e1s detalladamente en la secci\u00f3n \"Acciones explicadas\".</p>"},{"location":"manual_de_usuario/#11-python-package","title":"1.1 Python Package","text":"<ul> <li>Prop\u00f3sito: Instala dependencias, ejecuta an\u00e1lisis de calidad con flake8 y corre los tests.</li> <li>Trigger: Push a cualquier rama o creaci\u00f3n de un Pull Request.</li> </ul>"},{"location":"manual_de_usuario/#12-generate-and-publish-documentation","title":"1.2 Generate and Publish Documentation","text":"<ul> <li>Prop\u00f3sito: Genera documentaci\u00f3n actualizada combinando docstrings del c\u00f3digo en <code>src/</code> con documentaci\u00f3n manual en <code>docs/</code>.</li> <li>Trigger: Push a <code>main</code> o de forma manual.</li> </ul>"},{"location":"manual_de_usuario/#13-upload-python-package","title":"1.3 Upload Python Package","text":"<ul> <li>Prop\u00f3sito: Crea un paquete Python y lo sube a Test PyPI con el nombre del release.</li> <li>Trigger: Publicaci\u00f3n de un release en GitHub.</li> </ul>"},{"location":"manual_de_usuario/#2-pipeline-de-trabajo-para-los-desarrolladores","title":"2. Pipeline de Trabajo para los Desarrolladores","text":""},{"location":"manual_de_usuario/#paso-1-clonar-el-repositorio","title":"Paso 1: Clonar el Repositorio","text":"<ol> <li> <p>Clona el repositorio en tu m\u00e1quina local:</p> <p><code>bash git clone https://github.com/capo-urjc/python-tools.git</code></p> <p>Accede al directorio del proyecto:</p> <p><code>bash cd proyecto</code></p> </li> </ol>"},{"location":"manual_de_usuario/#paso-2-desarrollar-la-funcionalidad","title":"Paso 2: Desarrollar la Funcionalidad","text":"<ol> <li> <p>Crea una nueva rama para trabajar en tu funcionalidad:</p> <p><code>bash git checkout -b feature/nueva-funcionalidad</code></p> </li> <li> <p>Realiza las siguientes tareas:</p> <ul> <li>2.1 Incluir tu c\u00f3digo: A\u00f1ade el c\u00f3digo necesario en los archivos correspondientes del proyecto.</li> <li>2.2 Desarrollar los tests unitarios: Escribe tests para validar la funcionalidad en la carpeta de tests.</li> <li>2.3 Documentar el c\u00f3digo: A\u00f1ade docstrings en formato Google y, si es necesario, actualiza la documentaci\u00f3n manual en la carpeta <code>docs/</code>. Debes a\u00f1adir tus archivos en docs/api.md en este formato \"::: src.capo_tools.ejemplo\"</li> </ul> </li> </ol>"},{"location":"manual_de_usuario/#paso-3-verificar-el-funcionamiento-correcto","title":"Paso 3: Verificar el Funcionamiento Correcto","text":"<ol> <li> <p>Si has a\u00f1adido nuevas dependencias:</p> <ul> <li>Inst\u00e1lalas y agr\u00e9galas de forma manual al archivo <code>pyproject.toml</code> en la secci\u00f3n [tool.pdm.dev-dependencies]:</li> </ul> <p><code>bash   pip install nombre-libreria</code>  2. Aseg\u00farate de que el c\u00f3digo pasa las acciones: - Python package: Lo puedes activar haciendo push a tu rama de desarrollo o a cualquier rama. Revisa el feedback de flake8 para la calidad del c\u00f3digo y el feedback de pytest con los tests unitarios. Modificar las restricciones de lint con flake8 si es necesario seg\u00fan tus requisitos, al igual que a la hora de pasar los tests con pypi. - Upload python package: Solo lo puedes activar publicando un realease, pero puedes hacer pruebas en tu rama. Revisa que el nombre de versi\u00f3n del tag del realease es correcto con el formato \"vX.X.X\". Verificar que el paquete se ha construido correctamente con twine. Por \u00faltimo, comprobar que se ha subido correctamente a TestPypi. - Generate and publish documentation: Lo puedes activar de forma manual es la pesta\u00f1a actions de Github, importante activarla en tu rama de desarrollo. Se activa automaticamente cuando se hace push a main. Comprueba en https://capo-urjc.github.io/python-tools/ que se ha subido la documentaci\u00f3n correctamente. La documentaci\u00f3n del c\u00f3digo est\u00e1 en el apartado API. Para ello tiene que estar en docs/api.md vuestros archivos a\u00f1adidos.</p> </li> </ol>"},{"location":"manual_de_usuario/#paso-4-crear-el-pull-request","title":"Paso 4: Crear el Pull Request","text":"<ol> <li> <p>Sube tus cambios a tu rama remota:</p> <p><code>bash git push origin feature/nueva-funcionalidad</code></p> </li> <li> <p>Abre un Pull Request en GitHub contra la rama <code>main</code>.</p> </li> <li> <p>Verifica que las acciones automatizadas en GitHub Actions se ejecuten correctamente:</p> <ul> <li>La acci\u00f3n Python Package debe pasar sin errores.</li> <li>La acci\u00f3n Generate and Publish Documentation debe generar la documentaci\u00f3n correctamente.</li> </ul> </li> </ol>"},{"location":"manual_de_usuario/#3-consideraciones-adicionales","title":"3. Consideraciones Adicionales","text":""},{"location":"manual_de_usuario/#errores-en-las-acciones","title":"Errores en las Acciones","text":"<ul> <li>Si alguna acci\u00f3n falla, revisa los logs en la pesta\u00f1a Actions de GitHub para identificar el problema.</li> <li>Soluciona los errores y haz un nuevo push.</li> </ul>"},{"location":"manual_de_usuario/#credenciales-para-test-pypi","title":"Credenciales para Test PyPI","text":"<ul> <li>Aseg\u00farate de que las credenciales est\u00e1n configuradas en los secrets del repositorio si necesitas publicar un paquete.</li> </ul>"},{"location":"manual_de_usuario/#resumen-del-pipeline-con-ejemplo","title":"Resumen del Pipeline con ejemplo","text":"<ol> <li> <p>Clonar el repositorio:     <code>bash     git clone https://github.com/capo-urjc/python-tools.git     cd proyecto</code></p> </li> <li> <p>Desarrollar la funcionalidad:</p> <ul> <li>Crear una rama:</li> </ul> <p><code>bash   git checkout -b feature/nueva-funcionalidad</code></p> <ul> <li>Incluir el c\u00f3digo.</li> <li>A\u00f1adir tests unitarios.</li> <li>Documentar el c\u00f3digo con docstrings y actualizar <code>docs/</code> si es necesario.</li> </ul> </li> <li> <p>Verificar el funcionamiento correcto:</p> <ul> <li>Si has a\u00f1adido nuevas dependencias, inst\u00e1lalas y agr\u00e9galas en <code>pyproject.toml</code></li> <li>Aseg\u00farate de que el c\u00f3digo pasa las acciones</li> </ul> </li> <li> <p>Crear el Pull Request:</p> <ul> <li>Subir los cambios:</li> </ul> <p><code>bash   git push origin feature/nueva-funcionalidad</code></p> <ul> <li>Abrir un Pull Request en GitHub.</li> </ul> </li> <li> <p>Confirmar que las acciones de GitHub se ejecuten correctamente:</p> <ul> <li>Validar que todas las acciones pasan sin errores.</li> </ul> </li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li> capo_tools<ul> <li> datasets<ul> <li> CAVE<ul> <li> dataset</li> <li> tools</li> <li> utils<ul> <li> downsampling</li> <li> extract_random_patch</li> </ul> </li> </ul> </li> <li> ETS2<ul> <li> dataset</li> <li> ets2_tools<ul> <li> depth_file</li> </ul> </li> <li> tools</li> </ul> </li> </ul> </li> <li> display<ul> <li> time_series</li> <li> tools<ul> <li> depth_tools</li> </ul> </li> </ul> </li> <li> pt_functions<ul> <li> ffts</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/capo_tools/","title":"Index","text":""},{"location":"reference/capo_tools/#capo_tools","title":"capo_tools","text":"<p>Modules:</p> <ul> <li> <code>datasets</code>           \u2013            </li> <li> <code>display</code>           \u2013            </li> <li> <code>pt_functions</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/datasets/","title":"Index","text":""},{"location":"reference/capo_tools/datasets/#capo_tools.datasets","title":"datasets","text":"<p>Modules:</p> <ul> <li> <code>CAVE</code>           \u2013            </li> <li> <code>ETS2</code>           \u2013            <p>ETS2 dataset module.</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/","title":"Index","text":""},{"location":"reference/capo_tools/datasets/CAVE/#capo_tools.datasets.CAVE","title":"CAVE","text":"<p>Modules:</p> <ul> <li> <code>dataset</code>           \u2013            </li> <li> <code>utils</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/dataset/","title":"Dataset","text":""},{"location":"reference/capo_tools/datasets/CAVE/dataset/#capo_tools.datasets.CAVE.dataset","title":"dataset","text":"<p>Classes:</p> <ul> <li> <code>CAVEDataset</code>           \u2013            <p>Dataset class for loading Hyperspectral images dataset (CAVE).</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/dataset/#capo_tools.datasets.CAVE.dataset.CAVEDataset","title":"CAVEDataset","text":"<pre><code>CAVEDataset(root_dir: str, patch_size: tuple, transform=None, download=False, mode='train')\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Dataset class for loading Hyperspectral images dataset (CAVE).</p> <p>Parameters:</p> <ul> <li> <code>root_dir</code>               (<code>str</code>)           \u2013            <p>Root directory where the dataset is stored.</p> </li> <li> <code>patch_size</code>               (<code>tuple</code>)           \u2013            <p>Size of the patch to be extracted from the images.</p> </li> <li> <code>transform</code>               (<code>callable</code>, default:                   <code>None</code> )           \u2013            <p>Optional transform to be applied on the samples.</p> </li> <li> <code>download</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, downloads the dataset from the internet if it's not already downloaded.</p> </li> <li> <code>mode</code>               (<code>str</code>, default:                   <code>'train'</code> )           \u2013            <p>Mode of the dataset ('train', 'valid', 'test'.).</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/tools/","title":"Tools","text":""},{"location":"reference/capo_tools/datasets/CAVE/tools/#capo_tools.datasets.CAVE.tools","title":"tools","text":""},{"location":"reference/capo_tools/datasets/CAVE/utils/","title":"Index","text":""},{"location":"reference/capo_tools/datasets/CAVE/utils/#capo_tools.datasets.CAVE.utils","title":"utils","text":"<p>Modules:</p> <ul> <li> <code>downsampling</code>           \u2013            </li> <li> <code>extract_random_patch</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/utils/downsampling/","title":"Downsampling","text":""},{"location":"reference/capo_tools/datasets/CAVE/utils/downsampling/#capo_tools.datasets.CAVE.utils.downsampling","title":"downsampling","text":"<p>Classes:</p> <ul> <li> <code>DownSampling_LossChannels</code>           \u2013            <p>Crop the given image at a random location.</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/utils/downsampling/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels","title":"DownSampling_LossChannels","text":"<pre><code>DownSampling_LossChannels(loss_ch=None)\n</code></pre> <p>               Bases: <code>Module</code></p> <p>Crop the given image at a random location.</p> <p>Methods:</p> <ul> <li> <code>forward</code>             \u2013              <p>Args:</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/utils/downsampling/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels.forward","title":"forward","text":"<pre><code>forward(y)\n</code></pre> <p>Parameters:</p> <ul> <li> <code>y</code>               (<code>Tensor</code>)           \u2013            <p>Image to be downsampled channel-wise. [ch, height, width]</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y}</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/utils/extract_random_patch/","title":"Extract random patch","text":""},{"location":"reference/capo_tools/datasets/CAVE/utils/extract_random_patch/#capo_tools.datasets.CAVE.utils.extract_random_patch","title":"extract_random_patch","text":"<p>Functions:</p> <ul> <li> <code>extract_random_patch</code>             \u2013              <p>Extracts a random patch of size 'size' from the input image.</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/CAVE/utils/extract_random_patch/#capo_tools.datasets.CAVE.utils.extract_random_patch.extract_random_patch","title":"extract_random_patch","text":"<pre><code>extract_random_patch(image, size)\n</code></pre> <p>Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries.</p> <p>Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch.</p> <p>Returns: - patch: NumPy array representing the extracted patch.</p>"},{"location":"reference/capo_tools/datasets/ETS2/","title":"Index","text":""},{"location":"reference/capo_tools/datasets/ETS2/#capo_tools.datasets.ETS2","title":"ETS2","text":"<p>ETS2 dataset module.</p> <p>Modules:</p> <ul> <li> <code>dataset</code>           \u2013            <p>Pytorch Dataset for ETS2 dataset, single frame</p> </li> <li> <code>ets2_tools</code>           \u2013            <p>Tools for ETS2 dataset</p> </li> <li> <code>transforms</code>           \u2013            <p>Pytorch Transforms for ETS2 dataset</p> </li> </ul> <p>Modules:</p> <ul> <li> <code>dataset</code>           \u2013            </li> <li> <code>ets2_tools</code>           \u2013            </li> <li> <code>tools</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/dataset/","title":"Dataset","text":""},{"location":"reference/capo_tools/datasets/ETS2/dataset/#capo_tools.datasets.ETS2.dataset","title":"dataset","text":"<p>Classes:</p> <ul> <li> <code>ETS2Dataset</code>           \u2013            <p>Pytorch Dataset for ETS2 dataset, single frame</p> </li> <li> <code>ETS2DatasetVideo</code>           \u2013            <p>Pytorch Dataset for ETS2 dataset, video sequence</p> </li> <li> <code>ToTensor</code>           \u2013            <p>Convert ETS2 sample to Tensors</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/dataset/#capo_tools.datasets.ETS2.dataset.ETS2Dataset","title":"ETS2Dataset","text":"<pre><code>ETS2Dataset(data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None)\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Pytorch Dataset for ETS2 dataset, single frame</p> <p>The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30</p> <p>Attributes:</p> <ul> <li> <code>data_path</code>               (<code>str</code>)           \u2013            <p>Path to the dataset</p> </li> <li> <code>is_train</code>               (<code>bool</code>)           \u2013            <p>Whether the dataset is for training or not</p> </li> <li> <code>data</code>               (<code>DataFrame</code>)           \u2013            <p>Telemetry data</p> </li> <li> <code>indexes</code>               (<code>list</code>)           \u2013            <p>List of indexes to use from the dataset</p> </li> <li> <code>transform</code>               (<code>callable</code>)           \u2013            <p>Optional transform to be applied to the sample</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/dataset/#capo_tools.datasets.ETS2.dataset.ETS2DatasetVideo","title":"ETS2DatasetVideo","text":"<pre><code>ETS2DatasetVideo(indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0)\n</code></pre> <p>               Bases: <code>Dataset</code></p> <p>Pytorch Dataset for ETS2 dataset, video sequence</p> <p>The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30</p>"},{"location":"reference/capo_tools/datasets/ETS2/dataset/#capo_tools.datasets.ETS2.dataset.ToTensor","title":"ToTensor","text":"<p>               Bases: <code>object</code></p> <p>Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors</p>"},{"location":"reference/capo_tools/datasets/ETS2/tools/","title":"Tools","text":""},{"location":"reference/capo_tools/datasets/ETS2/tools/#capo_tools.datasets.ETS2.tools","title":"tools","text":"<p>Functions:</p> <ul> <li> <code>is_numpy_image</code>             \u2013              <p>Given an object, checks if it is a numpy image.</p> </li> <li> <code>is_pil_image</code>             \u2013              <p>Given an object, checks if it is a PIL image.</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/tools/#capo_tools.datasets.ETS2.tools.is_numpy_image","title":"is_numpy_image","text":"<pre><code>is_numpy_image(img)\n</code></pre> <p>Given an object, checks if it is a numpy image. Be careful there is no way to check if a numpy array is an image, this function checks if the input is a numpy array and if it has 2 or 3 dimensions. img (object): object to check if it is a numpy image</p>"},{"location":"reference/capo_tools/datasets/ETS2/tools/#capo_tools.datasets.ETS2.tools.is_pil_image","title":"is_pil_image","text":"<pre><code>is_pil_image(img)\n</code></pre> <p>Given an object, checks if it is a PIL image. img (object): object to check if it is a PIL image</p>"},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/","title":"Index","text":""},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/#capo_tools.datasets.ETS2.ets2_tools","title":"ets2_tools","text":"<p>Modules:</p> <ul> <li> <code>depth_file</code>           \u2013            </li> </ul> <p>Functions:</p> <ul> <li> <code>get_data</code>             \u2013              <p>Get the telemetry data from the dataset</p> </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/#capo_tools.datasets.ETS2.ets2_tools.get_data","title":"get_data","text":"<pre><code>get_data(path: str, include_static_frames: bool = True, include_night_frames: bool = True)\n</code></pre> <p>Get the telemetry data from the dataset</p>"},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/depth_file/","title":"Depth file","text":""},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/depth_file/#capo_tools.datasets.ETS2.ets2_tools.depth_file","title":"depth_file","text":"<p>Classes:</p> <ul> <li> <code>ETS2DepthFile</code>           \u2013            </li> <li> <code>ETS2DepthFileHeader</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/depth_file/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile","title":"ETS2DepthFile","text":"<pre><code>ETS2DepthFile(file: str, far_value: float = 10000, eager_load: bool = True)\n</code></pre> <pre><code>file ():\nfar_value ():\neager_load ():\n</code></pre>"},{"location":"reference/capo_tools/datasets/ETS2/ets2_tools/depth_file/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader","title":"ETS2DepthFileHeader","text":"<pre><code>ETS2DepthFileHeader(data)\n</code></pre> <pre><code>data ():\n</code></pre>"},{"location":"reference/capo_tools/display/","title":"Index","text":""},{"location":"reference/capo_tools/display/#capo_tools.display","title":"display","text":"<p>Modules:</p> <ul> <li> <code>time_series</code>           \u2013            </li> <li> <code>tools</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/display/time_series/","title":"Time series","text":""},{"location":"reference/capo_tools/display/time_series/#capo_tools.display.time_series","title":"time_series","text":"<p>Functions:</p> <ul> <li> <code>plot_time_series</code>             \u2013              <p>Visualizes and compares real and predicted time series using Plotly.</p> </li> </ul>"},{"location":"reference/capo_tools/display/time_series/#capo_tools.display.time_series.plot_time_series","title":"plot_time_series","text":"<pre><code>plot_time_series(y: ndarray, y_hat: ndarray, x_values=None, title: str = None, xlabel: str = None, ylabel: str = None, path_to_save: str = None, colors: list = ['blue', 'red'], markers: list = ['circle', 'square'], styles: list = ['solid', 'dash'], x_dtick=None, y_dtick=None, y_range: tuple = None, legend: bool = True, show_grid: bool = True, show: bool = False, height: int = 500, aspect_ratio: float = 1.5) -&gt; Figure\n</code></pre> <p>Visualizes and compares real and predicted time series using Plotly.</p> <p>Parameters:</p> <ul> <li> <code>y</code>               (<code>ndarray</code>)           \u2013            <p>Array with the actual values of the time series.</p> </li> <li> <code>y_hat</code>               (<code>ndarray</code>)           \u2013            <p>Array with the predicted values of the time series.</p> </li> <li> <code>x_values</code>               (<code>list</code>, default:                   <code>None</code> )           \u2013            <p>List of values for the X-axis (default is a numeric range).</p> </li> <li> <code>title</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Title of the plot.</p> </li> <li> <code>xlabel</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Label for the X-axis.</p> </li> <li> <code>ylabel</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Label for the Y-axis.</p> </li> <li> <code>path_to_save</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Path to save the plot as an HTML file. If None, the plot won't be saved.</p> </li> <li> <code>colors</code>               (<code>list</code>, default:                   <code>['blue', 'red']</code> )           \u2013            <p>List of colors for the series (default <code>[\"blue\", \"red\"]</code>).</p> </li> <li> <code>markers</code>               (<code>list</code>, default:                   <code>['circle', 'square']</code> )           \u2013            <p>List of markers for the series (default <code>[\"circle\", \"square\"]</code>).</p> </li> <li> <code>styles</code>               (<code>list</code>, default:                   <code>['solid', 'dash']</code> )           \u2013            <p>List of line styles for the series (default <code>[\"solid\", \"dash\"]</code>).</p> </li> <li> <code>x_dtick</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Granularity for the X-axis ticks (e.g., <code>\"D1\"</code> for days, <code>\"M1\"</code> for months).</p> </li> <li> <code>y_dtick</code>               (<code>int</code>, default:                   <code>None</code> )           \u2013            <p>Granularity for the Y-axis ticks.</p> </li> <li> <code>y_range</code>               (<code>tuple</code>, default:                   <code>None</code> )           \u2013            <p>Tuple <code>(min, max)</code> defining the Y-axis range. If None, it is set automatically.</p> </li> <li> <code>legend</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to show the legend (default is <code>True</code>).</p> </li> <li> <code>show_grid</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to show the grid (default is <code>True</code>).</p> </li> <li> <code>show</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display the plot (default is <code>False</code>).</p> </li> <li> <code>height</code>               (<code>int</code>, default:                   <code>500</code> )           \u2013            <p>Height of the plot in pixels (default is <code>500</code>).</p> </li> <li> <code>aspect_ratio</code>               (<code>float</code>, default:                   <code>1.5</code> )           \u2013            <p>Width-to-height ratio of the plot (default is <code>1.5</code>, meaning width = <code>1.5 * height</code>).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Figure</code>           \u2013            <p>matplotlib.Figure</p> </li> </ul>"},{"location":"reference/capo_tools/display/tools/","title":"Index","text":""},{"location":"reference/capo_tools/display/tools/#capo_tools.display.tools","title":"tools","text":"<p>Modules:</p> <ul> <li> <code>depth_tools</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/display/tools/depth_tools/","title":"Depth tools","text":""},{"location":"reference/capo_tools/display/tools/depth_tools/#capo_tools.display.tools.depth_tools","title":"depth_tools","text":"<p>Functions:</p> <ul> <li> <code>colorize</code>             \u2013              <p>Colorize the data using the specified colormap</p> </li> <li> <code>normalize</code>             \u2013              <p>Normalize the data to the range [0, 1]</p> </li> </ul>"},{"location":"reference/capo_tools/display/tools/depth_tools/#capo_tools.display.tools.depth_tools.colorize","title":"colorize","text":"<pre><code>colorize(data, colormap_name='magma', normalize_data=True, invert=False)\n</code></pre> <p>Colorize the data using the specified colormap</p>"},{"location":"reference/capo_tools/display/tools/depth_tools/#capo_tools.display.tools.depth_tools.normalize","title":"normalize","text":"<pre><code>normalize(data)\n</code></pre> <p>Normalize the data to the range [0, 1]</p>"},{"location":"reference/capo_tools/pt_functions/","title":"Index","text":""},{"location":"reference/capo_tools/pt_functions/#capo_tools.pt_functions","title":"pt_functions","text":"<p>Modules:</p> <ul> <li> <code>ffts</code>           \u2013            </li> </ul>"},{"location":"reference/capo_tools/pt_functions/ffts/","title":"Ffts","text":""},{"location":"reference/capo_tools/pt_functions/ffts/#capo_tools.pt_functions.ffts","title":"ffts","text":"<p>Functions:</p> <ul> <li> <code>ffp3d</code>             \u2013              <p>Perform 3D Fast Fourier Transform and Convolution in the frequency domain.</p> </li> <li> <code>psf2otf3d</code>             \u2013              <p>Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain.</p> </li> </ul>"},{"location":"reference/capo_tools/pt_functions/ffts/#capo_tools.pt_functions.ffts.ffp3d","title":"ffp3d","text":"<pre><code>ffp3d(tensor, kernel)\n</code></pre> <p>Perform 3D Fast Fourier Transform and Convolution in the frequency domain.</p> <p>Parameters:</p> <ul> <li> <code>tensor</code>               (<code>Tensor</code>)           \u2013            <p>Input tensor.</p> </li> <li> <code>kernel</code>               (<code>Tensor</code>)           \u2013            <p>Convolution kernel.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>torch.Tensor: Convolved tensor.</p> </li> </ul>"},{"location":"reference/capo_tools/pt_functions/ffts/#capo_tools.pt_functions.ffts.psf2otf3d","title":"psf2otf3d","text":"<pre><code>psf2otf3d(kernel, input_shape, n=1)\n</code></pre> <p>Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain.</p> <p>Parameters:</p> <ul> <li> <code>kernel</code>               (<code>Tensor</code>)           \u2013            <p>The PSF kernel.</p> </li> <li> <code>input_shape</code>               (<code>tuple</code>)           \u2013            <p>Shape of the input tensor (channels, height, width).</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of samples. Defaults to 1.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>torch.Tensor: OTF of the kernel.</p> </li> </ul>"}]}