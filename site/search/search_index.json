{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenido a la Documentaci\u00f3n de python-tools \u00b6 Este proyecto es una herramienta escrita en Python que hace ... Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo usar, configurar y desarrollar la herramienta. Contenido \u00b6 Introducci\u00f3n Instalaci\u00f3n Referencias de la API Introducci\u00f3n \u00b6 breve descripci\u00f3n del proyecto, sus objetivos y c\u00f3mo puede ayudar a los usuarios. Instalaci\u00f3n \u00b6 Para instalar el proyecto, puedes usar: ```bash pip install ...","title":"Home"},{"location":"#bienvenido-a-la-documentacion-de-python-tools","text":"Este proyecto es una herramienta escrita en Python que hace ... Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo usar, configurar y desarrollar la herramienta.","title":"Bienvenido a la Documentaci\u00f3n de python-tools"},{"location":"#contenido","text":"Introducci\u00f3n Instalaci\u00f3n Referencias de la API","title":"Contenido"},{"location":"#introduccion","text":"breve descripci\u00f3n del proyecto, sus objetivos y c\u00f3mo puede ayudar a los usuarios.","title":"Introducci\u00f3n"},{"location":"#instalacion","text":"Para instalar el proyecto, puedes usar: ```bash pip install ...","title":"Instalaci\u00f3n"},{"location":"api/","text":"API Reference \u00b6 CAVEDataset \u00b6 Bases: Dataset Dataset class for loading Hyperspectral images dataset (CAVE). Source code in src/capo_tools/datasets/CAVE/dataset.py class CAVEDataset(Dataset): \"\"\" Dataset class for loading Hyperspectral images dataset (CAVE). \"\"\" def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample __getitem__(idx) \u00b6 Get a sample from the dataset at the specified index. Parameters: Name Type Description Default idx int Index of the sample to retrieve. required Returns: Type Description torch.Tensor: Transformed sample. Source code in src/capo_tools/datasets/CAVE/dataset.py def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample __init__(root_dir, patch_size, transform=None, download=False, mode='train') \u00b6 Initializes the dataset by loading the data. Parameters: Name Type Description Default root_dir str Root directory where the dataset is stored. required patch_size tuple Size of the patch to be extracted from the images. required transform callable Optional transform to be applied on the samples. None download bool If True, downloads the dataset from the internet if it's not already downloaded. False mode str Mode of the dataset ('train', 'valid', 'test'.). 'train' Source code in src/capo_tools/datasets/CAVE/dataset.py def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') __len__() \u00b6 Get the total number of images in the dataset. Returns: Name Type Description int Total number of images. Source code in src/capo_tools/datasets/CAVE/dataset.py def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) DownSampling_LossChannels \u00b6 Bases: Module Crop the given image at a random location. Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py class DownSampling_LossChannels(torch.nn.Module): \"\"\" Crop the given image at a random location. \"\"\" def __init__(self, loss_ch=None): super().__init__() self.loss_ch = loss_ch or list(range(1, 31, 2)) def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y} forward(y) \u00b6 Parameters: Name Type Description Default y Tensor Image to be downsampled channel-wise. [ch, height, width] required Returns: Type Description Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y} extract_random_patch(image, size) \u00b6 Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. Source code in src/capo_tools/datasets/CAVE/utils/extract_random_patch.py def extract_random_patch(image, size): \"\"\" Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. \"\"\" # Get image dimensions img_height, img_width = image.shape[:2] patch_height, patch_width = size # Choose random starting coordinates for the patch start_row = np.random.randint(0, img_height - patch_height + 1) start_col = np.random.randint(0, img_width - patch_width + 1) # Extract the patch patch = image[start_row:start_row + patch_height, start_col:start_col + patch_width] return patch ETS2Dataset \u00b6 Bases: Dataset Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2Dataset(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None): super(ETS2Dataset, self).__init__() self.data_path = data_path self.image_type = image_type self.is_train = is_train self.data = get_data(self.data_path) self.indexes = indexes if indexes is not None else list(range(len(self.data))) self.transform = transform if transform is not None else ToTensor() def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes) __getitem__(item) \u00b6 Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata Source code in src/capo_tools/datasets/ETS2/dataset.py def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample __len__() \u00b6 Get the number of frames in the dataset Source code in src/capo_tools/datasets/ETS2/dataset.py def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes) ETS2DatasetVideo \u00b6 Bases: Dataset Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2DatasetVideo(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0): super(ETS2DatasetVideo, self).__init__() self.data_path = data_path self.is_train = is_train self.data_indexes = indexes self.data = get_data(data_path) self.transform = transform self.maxDepth = max_depth def __getitem__(self, item): sequence_start_index = self.data_indexes[item] # TODO: parametrize number of frames in sequence sequence_end_index = sequence_start_index + 10 data_rows = self.data.iloc[sequence_start_index:sequence_end_index, :] files = [os.path.join(self.data_path, x) for x in (data_rows['session'] + \"/\" + data_rows['capture']).tolist()] x = [] y = [] metadata = [] for index, file in enumerate(files): file_path = f\"{file}.jpg\" image = Image.open(file_path) depth_file = read_depth_file(f\"{file}.depth.raw\") header = depth_file['header'] depth = -depth_file['data'] depth_shape = (header['height'], header['width'], 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file} sample = self.transform(sample) x.append(sample['image']) y.append(sample['depth']) data_row = data_rows.iloc[index] metadata.append({\"path\": file_path, \"session\": data_row['session'], \"capture\": data_row['capture']}) x = torch.stack((x)) y = torch.stack((y)) return x, y, metadata def __len__(self): return len(self.data_indexes) ToTensor \u00b6 Bases: object Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors Source code in src/capo_tools/datasets/ETS2/dataset.py class ToTensor(object): \"\"\" Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors \"\"\" def __call__(self, sample): image, depth = sample['image'], sample['depth'] image = pil_to_tensor(image).float() depth = torch.from_numpy(depth).float().permute(2, 0, 1) metadata = sample['metadata'] frame = sample['frame'] return {'image': image, 'depth': depth, 'frame': frame, 'metadata': metadata} ETS2DepthFile \u00b6 Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFile: def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() def _read_depth_file(self): data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self.header = ETS2DepthFileHeader(data) # TODO: review, find a better way to do this, # self.is_real_depth = (self.header.bit_depth == 16) if self.eager_load: self._read_data(data) del data def _read_depth_data(self, file_data): data_bytes = self.header.bit_depth // 8 denorm = pow(2, 24) - 1 # TODO: Review, this hardcoded 28 should be self.header.offset? format = '<%sU' % int((self.header.size - 26) / data_bytes) self.data = np.array(rawutil.unpack(format, file_data[self.header.offset:])) # self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) self.data = self.data / denorm # data = normalize(data) def _read_realdepth_data(self, file_data): data_bytes = self.header.bit_depth // 8 # TODO: Review, make sure this is the same, as np.from_buffer is much much faster than rawutil.unpack # TODO: Review, this hardcoded 28 should be self.header.offset? # format = '<%se' % int((self.header.size - 28) / data_bytes) # self.data = -np.array(rawutil.unpack(format, file_data[self.header.offset:])) self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) # NaN handling data_nans = np.count_nonzero(np.isnan(self.data)) if data_nans > 0: warnings.warn(f\"{os.path.join(self.base, f'{self.file_name}{self.ext}')}: There are {data_nans} NaN values in depth data, transforming them to zeros\") self.data[np.isnan(self.data)] = 0 def _read_data(self, data): if self.is_real_depth: self._read_realdepth_data(data) else: self._read_depth_data(data) def get_data(self): if self.data is None: data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self._read_data(data) del data return self.data def size(self): return self.header.width, self.header.height __init__(file, far_value=10000, eager_load=True) \u00b6 ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() ETS2DepthFileHeader \u00b6 Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFileHeader: def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) def _read_header(self, data): if len(data) == 3525146: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"offset\": struct.unpack('<l', data[22:26])[0], \"bit_depth\": 24 } else: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"bit_depth\": struct.unpack('<h', data[22:24])[0], \"offset\": struct.unpack('<l', data[24:28])[0] } self.__dict__.update(header) del header def __str__(self): return (f\"magic: {self.magic}, \" f\"size: {self.size}, \" f\"widht: {self.width}, \" f\"height: {self.height}, \" f\"minimum value: {self.min_val}, \" f\"maximum value: {self.max_val}, \" f\"bit depth: {self.bit_depth}, \" f\"offset: {self.offset}\") __init__(data) \u00b6 ETS2 Datset depth file header Args: data (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) ffp3d(tensor, kernel) \u00b6 Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Parameters: Name Type Description Default tensor Tensor Input tensor. required kernel Tensor Convolution kernel. required Returns: Type Description torch.Tensor: Convolved tensor. Source code in src/capo_tools/pt_functions/ffts.py def ffp3d(tensor, kernel): \"\"\" Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Args: tensor (torch.Tensor): Input tensor. kernel (torch.Tensor): Convolution kernel. Returns: torch.Tensor: Convolved tensor. \"\"\" c_org, h_org, w_org = tensor.size() kc, kh, kw = kernel.size() pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the input tensor tensor_pad = F.pad(tensor, (pad_w, pad_w, pad_h, pad_h, pad_c, pad_c)) c, h, w = tensor_pad.size() # Compute FFT of kernel and input tensor kernel_fft = psf2otf3d(kernel, tensor_pad.size()) tensor_fft = torch.fft.fftn(tensor_pad, s=(c, h, w)) # Compute inverse FFT and extract the valid part k_conv_t = torch.fft.ifftn(kernel_fft * tensor_fft)[pad_c:pad_c + c_org, pad_h:pad_h + h_org, pad_w:pad_w + w_org] return k_conv_t psf2otf3d(kernel, input_shape, n=1) \u00b6 Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Parameters: Name Type Description Default kernel Tensor The PSF kernel. required input_shape tuple Shape of the input tensor (channels, height, width). required n int Number of samples. Defaults to 1. 1 Returns: Type Description torch.Tensor: OTF of the kernel. Source code in src/capo_tools/pt_functions/ffts.py def psf2otf3d(kernel, input_shape, n=1): \"\"\" Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Args: kernel (torch.Tensor): The PSF kernel. input_shape (tuple): Shape of the input tensor (channels, height, width). n (int): Number of samples. Defaults to 1. Returns: torch.Tensor: OTF of the kernel. \"\"\" kc, kh, kw = kernel.size() c, h, w = input_shape pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the kernel and roll it kernel_pad = F.pad(kernel, (0, w - kw, 0, h - kh, 0, c - kc), \"constant\", 0) kernel_pad_roll = torch.roll(kernel_pad, shifts=(-pad_c, -pad_h, -pad_w), dims=(0, 1, 2)) # Compute the OTF using FFT kernel_otf = torch.fft.fftn(kernel_pad_roll, s=(c, h, w)) return kernel_otf","title":"API"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset","text":"Bases: Dataset Dataset class for loading Hyperspectral images dataset (CAVE). Source code in src/capo_tools/datasets/CAVE/dataset.py class CAVEDataset(Dataset): \"\"\" Dataset class for loading Hyperspectral images dataset (CAVE). \"\"\" def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample","title":"CAVEDataset"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__getitem__","text":"Get a sample from the dataset at the specified index. Parameters: Name Type Description Default idx int Index of the sample to retrieve. required Returns: Type Description torch.Tensor: Transformed sample. Source code in src/capo_tools/datasets/CAVE/dataset.py def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample","title":"__getitem__"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__init__","text":"Initializes the dataset by loading the data. Parameters: Name Type Description Default root_dir str Root directory where the dataset is stored. required patch_size tuple Size of the patch to be extracted from the images. required transform callable Optional transform to be applied on the samples. None download bool If True, downloads the dataset from the internet if it's not already downloaded. False mode str Mode of the dataset ('train', 'valid', 'test'.). 'train' Source code in src/capo_tools/datasets/CAVE/dataset.py def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.')","title":"__init__"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__len__","text":"Get the total number of images in the dataset. Returns: Name Type Description int Total number of images. Source code in src/capo_tools/datasets/CAVE/dataset.py def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images)","title":"__len__"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels","text":"Bases: Module Crop the given image at a random location. Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py class DownSampling_LossChannels(torch.nn.Module): \"\"\" Crop the given image at a random location. \"\"\" def __init__(self, loss_ch=None): super().__init__() self.loss_ch = loss_ch or list(range(1, 31, 2)) def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y}","title":"DownSampling_LossChannels"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels.forward","text":"Parameters: Name Type Description Default y Tensor Image to be downsampled channel-wise. [ch, height, width] required Returns: Type Description Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y}","title":"forward"},{"location":"api/#capo_tools.datasets.CAVE.utils.extract_random_patch.extract_random_patch","text":"Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. Source code in src/capo_tools/datasets/CAVE/utils/extract_random_patch.py def extract_random_patch(image, size): \"\"\" Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. \"\"\" # Get image dimensions img_height, img_width = image.shape[:2] patch_height, patch_width = size # Choose random starting coordinates for the patch start_row = np.random.randint(0, img_height - patch_height + 1) start_col = np.random.randint(0, img_width - patch_width + 1) # Extract the patch patch = image[start_row:start_row + patch_height, start_col:start_col + patch_width] return patch","title":"extract_random_patch"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset","text":"Bases: Dataset Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2Dataset(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None): super(ETS2Dataset, self).__init__() self.data_path = data_path self.image_type = image_type self.is_train = is_train self.data = get_data(self.data_path) self.indexes = indexes if indexes is not None else list(range(len(self.data))) self.transform = transform if transform is not None else ToTensor() def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes)","title":"ETS2Dataset"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset.__getitem__","text":"Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata Source code in src/capo_tools/datasets/ETS2/dataset.py def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample","title":"__getitem__"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset.__len__","text":"Get the number of frames in the dataset Source code in src/capo_tools/datasets/ETS2/dataset.py def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes)","title":"__len__"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2DatasetVideo","text":"Bases: Dataset Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2DatasetVideo(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0): super(ETS2DatasetVideo, self).__init__() self.data_path = data_path self.is_train = is_train self.data_indexes = indexes self.data = get_data(data_path) self.transform = transform self.maxDepth = max_depth def __getitem__(self, item): sequence_start_index = self.data_indexes[item] # TODO: parametrize number of frames in sequence sequence_end_index = sequence_start_index + 10 data_rows = self.data.iloc[sequence_start_index:sequence_end_index, :] files = [os.path.join(self.data_path, x) for x in (data_rows['session'] + \"/\" + data_rows['capture']).tolist()] x = [] y = [] metadata = [] for index, file in enumerate(files): file_path = f\"{file}.jpg\" image = Image.open(file_path) depth_file = read_depth_file(f\"{file}.depth.raw\") header = depth_file['header'] depth = -depth_file['data'] depth_shape = (header['height'], header['width'], 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file} sample = self.transform(sample) x.append(sample['image']) y.append(sample['depth']) data_row = data_rows.iloc[index] metadata.append({\"path\": file_path, \"session\": data_row['session'], \"capture\": data_row['capture']}) x = torch.stack((x)) y = torch.stack((y)) return x, y, metadata def __len__(self): return len(self.data_indexes)","title":"ETS2DatasetVideo"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ToTensor","text":"Bases: object Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors Source code in src/capo_tools/datasets/ETS2/dataset.py class ToTensor(object): \"\"\" Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors \"\"\" def __call__(self, sample): image, depth = sample['image'], sample['depth'] image = pil_to_tensor(image).float() depth = torch.from_numpy(depth).float().permute(2, 0, 1) metadata = sample['metadata'] frame = sample['frame'] return {'image': image, 'depth': depth, 'frame': frame, 'metadata': metadata}","title":"ToTensor"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile","text":"Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFile: def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() def _read_depth_file(self): data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self.header = ETS2DepthFileHeader(data) # TODO: review, find a better way to do this, # self.is_real_depth = (self.header.bit_depth == 16) if self.eager_load: self._read_data(data) del data def _read_depth_data(self, file_data): data_bytes = self.header.bit_depth // 8 denorm = pow(2, 24) - 1 # TODO: Review, this hardcoded 28 should be self.header.offset? format = '<%sU' % int((self.header.size - 26) / data_bytes) self.data = np.array(rawutil.unpack(format, file_data[self.header.offset:])) # self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) self.data = self.data / denorm # data = normalize(data) def _read_realdepth_data(self, file_data): data_bytes = self.header.bit_depth // 8 # TODO: Review, make sure this is the same, as np.from_buffer is much much faster than rawutil.unpack # TODO: Review, this hardcoded 28 should be self.header.offset? # format = '<%se' % int((self.header.size - 28) / data_bytes) # self.data = -np.array(rawutil.unpack(format, file_data[self.header.offset:])) self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) # NaN handling data_nans = np.count_nonzero(np.isnan(self.data)) if data_nans > 0: warnings.warn(f\"{os.path.join(self.base, f'{self.file_name}{self.ext}')}: There are {data_nans} NaN values in depth data, transforming them to zeros\") self.data[np.isnan(self.data)] = 0 def _read_data(self, data): if self.is_real_depth: self._read_realdepth_data(data) else: self._read_depth_data(data) def get_data(self): if self.data is None: data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self._read_data(data) del data return self.data def size(self): return self.header.width, self.header.height","title":"ETS2DepthFile"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile.__init__","text":"ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file()","title":"__init__"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader","text":"Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFileHeader: def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) def _read_header(self, data): if len(data) == 3525146: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"offset\": struct.unpack('<l', data[22:26])[0], \"bit_depth\": 24 } else: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"bit_depth\": struct.unpack('<h', data[22:24])[0], \"offset\": struct.unpack('<l', data[24:28])[0] } self.__dict__.update(header) del header def __str__(self): return (f\"magic: {self.magic}, \" f\"size: {self.size}, \" f\"widht: {self.width}, \" f\"height: {self.height}, \" f\"minimum value: {self.min_val}, \" f\"maximum value: {self.max_val}, \" f\"bit depth: {self.bit_depth}, \" f\"offset: {self.offset}\")","title":"ETS2DepthFileHeader"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader.__init__","text":"ETS2 Datset depth file header Args: data (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data)","title":"__init__"},{"location":"api/#capo_tools.pt_functions.ffts.ffp3d","text":"Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Parameters: Name Type Description Default tensor Tensor Input tensor. required kernel Tensor Convolution kernel. required Returns: Type Description torch.Tensor: Convolved tensor. Source code in src/capo_tools/pt_functions/ffts.py def ffp3d(tensor, kernel): \"\"\" Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Args: tensor (torch.Tensor): Input tensor. kernel (torch.Tensor): Convolution kernel. Returns: torch.Tensor: Convolved tensor. \"\"\" c_org, h_org, w_org = tensor.size() kc, kh, kw = kernel.size() pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the input tensor tensor_pad = F.pad(tensor, (pad_w, pad_w, pad_h, pad_h, pad_c, pad_c)) c, h, w = tensor_pad.size() # Compute FFT of kernel and input tensor kernel_fft = psf2otf3d(kernel, tensor_pad.size()) tensor_fft = torch.fft.fftn(tensor_pad, s=(c, h, w)) # Compute inverse FFT and extract the valid part k_conv_t = torch.fft.ifftn(kernel_fft * tensor_fft)[pad_c:pad_c + c_org, pad_h:pad_h + h_org, pad_w:pad_w + w_org] return k_conv_t","title":"ffp3d"},{"location":"api/#capo_tools.pt_functions.ffts.psf2otf3d","text":"Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Parameters: Name Type Description Default kernel Tensor The PSF kernel. required input_shape tuple Shape of the input tensor (channels, height, width). required n int Number of samples. Defaults to 1. 1 Returns: Type Description torch.Tensor: OTF of the kernel. Source code in src/capo_tools/pt_functions/ffts.py def psf2otf3d(kernel, input_shape, n=1): \"\"\" Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Args: kernel (torch.Tensor): The PSF kernel. input_shape (tuple): Shape of the input tensor (channels, height, width). n (int): Number of samples. Defaults to 1. Returns: torch.Tensor: OTF of the kernel. \"\"\" kc, kh, kw = kernel.size() c, h, w = input_shape pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the kernel and roll it kernel_pad = F.pad(kernel, (0, w - kw, 0, h - kh, 0, c - kc), \"constant\", 0) kernel_pad_roll = torch.roll(kernel_pad, shifts=(-pad_c, -pad_h, -pad_w), dims=(0, 1, 2)) # Compute the OTF using FFT kernel_otf = torch.fft.fftn(kernel_pad_roll, s=(c, h, w)) return kernel_otf","title":"psf2otf3d"}]}