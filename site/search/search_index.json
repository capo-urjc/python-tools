{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenido a la Documentaci\u00f3n de python-tools \u00b6 Este proyecto realizado por capo-urjc es una herramienta escrita en Python que hace ... Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo usar, configurar y desarrollar la herramienta. Contenido \u00b6 Introducci\u00f3n Instalaci\u00f3n Referencias de la API Introducci\u00f3n \u00b6 breve descripci\u00f3n del proyecto, sus objetivos y c\u00f3mo puede ayudar a los usuarios. Instalaci\u00f3n \u00b6 Para instalar el proyecto, puedes usar: ```bash pip install ...","title":"Home"},{"location":"#bienvenido-a-la-documentacion-de-python-tools","text":"Este proyecto realizado por capo-urjc es una herramienta escrita en Python que hace ... Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo usar, configurar y desarrollar la herramienta.","title":"Bienvenido a la Documentaci\u00f3n de python-tools"},{"location":"#contenido","text":"Introducci\u00f3n Instalaci\u00f3n Referencias de la API","title":"Contenido"},{"location":"#introduccion","text":"breve descripci\u00f3n del proyecto, sus objetivos y c\u00f3mo puede ayudar a los usuarios.","title":"Introducci\u00f3n"},{"location":"#instalacion","text":"Para instalar el proyecto, puedes usar: ```bash pip install ...","title":"Instalaci\u00f3n"},{"location":"acciones_explicadas/","text":"Acciones explicadas \u00b6 Este manual describe el funcionamiento de las tres acciones automatizadas disponibles en este proyecto. Cada acci\u00f3n est\u00e1 dise\u00f1ada para facilitar tareas clave como la gesti\u00f3n de dependencias, generaci\u00f3n de documentaci\u00f3n y despliegue de paquetes. Python package 1. Instalar dependencias, ejecutar linting y tests \u00b6 Descripci\u00f3n \u00b6 Esta acci\u00f3n instala las dependencias del proyecto, ejecuta an\u00e1lisis de c\u00f3digo con flake8 y realiza los tests definidos en el proyecto. Se activa en los siguientes casos: - Cuando se hace un push a la rama main . - Cuando se crea un pull request . Proceso \u00b6 Instala todas las dependencias necesarias definidas en los archivos del proyecto. Ejecuta flake8 para asegurarse de que el c\u00f3digo cumple con las normas de estilo y calidad. Corre los tests definidos, asegur\u00e1ndose de que el proyecto es funcional y no contiene errores. Activaci\u00f3n \u00b6 Trigger: Push a main o Pull Request. Generate and Publish Documentation 2. Generar documentaci\u00f3n autom\u00e1ticamente \u00b6 Descripci\u00f3n \u00b6 Esta acci\u00f3n genera la documentaci\u00f3n del proyecto combinando: - Los docstrings de los archivos ubicados en src/ . - Cualquier documentaci\u00f3n adicional definida manualmente en los archivos de la carpeta docs/ . El resultado es un sitio de documentaci\u00f3n actualizado autom\u00e1ticamente. Proceso \u00b6 Escanea los archivos en src/ y procesa los docstrings . Incluye la documentaci\u00f3n manual definida en docs/ . Genera un sitio est\u00e1tico que puede ser desplegado para consulta. Activaci\u00f3n \u00b6 Trigger: Push a main . Upload Python Package 3. Crear y publicar paquete en Test PyPI \u00b6 Descripci\u00f3n \u00b6 Esta acci\u00f3n automatiza la creaci\u00f3n y despliegue de un paquete Python en Test PyPI . El paquete incluye la etiqueta asociada al nombre del release publicado. Proceso \u00b6 Instala las dependencias necesarias para empaquetar el proyecto. Crea el paquete del proyecto usando herramientas como setuptools o pdm . Publica el paquete en Test PyPI con el nombre y la versi\u00f3n obtenidos del release. Activaci\u00f3n \u00b6 Trigger: Publicaci\u00f3n de un release. Notas \u00b6 El nombre del release se utiliza como etiqueta del paquete en Test PyPI. Aseg\u00farate de que las credenciales para Test PyPI est\u00e1n configuradas en los secrets del repositorio. Preguntas Frecuentes (FAQ) \u00b6 \u00bfQu\u00e9 sucede si una acci\u00f3n falla? \u00b6 Si alguna acci\u00f3n falla, revisa los logs generados en GitHub Actions para identificar el problema. Los errores comunes incluyen: - Dependencias faltantes. - Estilo de c\u00f3digo incorrecto (flake8). - Tests fallidos. \u00bfC\u00f3mo puedo personalizar estas acciones? \u00b6 Edita el archivo workflow.yml correspondiente en el directorio .github/workflows/ . Aseg\u00farate de seguir las normas de sintaxis de YAML. \u00bfD\u00f3nde puedo ver la documentaci\u00f3n generada? \u00b6 La documentaci\u00f3n generada se encuentra en la carpeta site/ , que puede ser desplegada en GitHub Pages o cualquier servidor est\u00e1tico. \u00a1Gracias por usar estas acciones automatizadas! Si necesitas m\u00e1s ayuda, no dudes en consultar con el equipo o revisar la configuraci\u00f3n de los workflows.","title":"Acciones explicadas"},{"location":"acciones_explicadas/#acciones-explicadas","text":"Este manual describe el funcionamiento de las tres acciones automatizadas disponibles en este proyecto. Cada acci\u00f3n est\u00e1 dise\u00f1ada para facilitar tareas clave como la gesti\u00f3n de dependencias, generaci\u00f3n de documentaci\u00f3n y despliegue de paquetes. Python package","title":"Acciones explicadas"},{"location":"acciones_explicadas/#1-instalar-dependencias-ejecutar-linting-y-tests","text":"","title":"1. Instalar dependencias, ejecutar linting y tests"},{"location":"acciones_explicadas/#descripcion","text":"Esta acci\u00f3n instala las dependencias del proyecto, ejecuta an\u00e1lisis de c\u00f3digo con flake8 y realiza los tests definidos en el proyecto. Se activa en los siguientes casos: - Cuando se hace un push a la rama main . - Cuando se crea un pull request .","title":"Descripci\u00f3n"},{"location":"acciones_explicadas/#proceso","text":"Instala todas las dependencias necesarias definidas en los archivos del proyecto. Ejecuta flake8 para asegurarse de que el c\u00f3digo cumple con las normas de estilo y calidad. Corre los tests definidos, asegur\u00e1ndose de que el proyecto es funcional y no contiene errores.","title":"Proceso"},{"location":"acciones_explicadas/#activacion","text":"Trigger: Push a main o Pull Request. Generate and Publish Documentation","title":"Activaci\u00f3n"},{"location":"acciones_explicadas/#2-generar-documentacion-automaticamente","text":"","title":"2. Generar documentaci\u00f3n autom\u00e1ticamente"},{"location":"acciones_explicadas/#descripcion_1","text":"Esta acci\u00f3n genera la documentaci\u00f3n del proyecto combinando: - Los docstrings de los archivos ubicados en src/ . - Cualquier documentaci\u00f3n adicional definida manualmente en los archivos de la carpeta docs/ . El resultado es un sitio de documentaci\u00f3n actualizado autom\u00e1ticamente.","title":"Descripci\u00f3n"},{"location":"acciones_explicadas/#proceso_1","text":"Escanea los archivos en src/ y procesa los docstrings . Incluye la documentaci\u00f3n manual definida en docs/ . Genera un sitio est\u00e1tico que puede ser desplegado para consulta.","title":"Proceso"},{"location":"acciones_explicadas/#activacion_1","text":"Trigger: Push a main . Upload Python Package","title":"Activaci\u00f3n"},{"location":"acciones_explicadas/#3-crear-y-publicar-paquete-en-test-pypi","text":"","title":"3. Crear y publicar paquete en Test PyPI"},{"location":"acciones_explicadas/#descripcion_2","text":"Esta acci\u00f3n automatiza la creaci\u00f3n y despliegue de un paquete Python en Test PyPI . El paquete incluye la etiqueta asociada al nombre del release publicado.","title":"Descripci\u00f3n"},{"location":"acciones_explicadas/#proceso_2","text":"Instala las dependencias necesarias para empaquetar el proyecto. Crea el paquete del proyecto usando herramientas como setuptools o pdm . Publica el paquete en Test PyPI con el nombre y la versi\u00f3n obtenidos del release.","title":"Proceso"},{"location":"acciones_explicadas/#activacion_2","text":"Trigger: Publicaci\u00f3n de un release.","title":"Activaci\u00f3n"},{"location":"acciones_explicadas/#notas","text":"El nombre del release se utiliza como etiqueta del paquete en Test PyPI. Aseg\u00farate de que las credenciales para Test PyPI est\u00e1n configuradas en los secrets del repositorio.","title":"Notas"},{"location":"acciones_explicadas/#preguntas-frecuentes-faq","text":"","title":"Preguntas Frecuentes (FAQ)"},{"location":"acciones_explicadas/#que-sucede-si-una-accion-falla","text":"Si alguna acci\u00f3n falla, revisa los logs generados en GitHub Actions para identificar el problema. Los errores comunes incluyen: - Dependencias faltantes. - Estilo de c\u00f3digo incorrecto (flake8). - Tests fallidos.","title":"\u00bfQu\u00e9 sucede si una acci\u00f3n falla?"},{"location":"acciones_explicadas/#como-puedo-personalizar-estas-acciones","text":"Edita el archivo workflow.yml correspondiente en el directorio .github/workflows/ . Aseg\u00farate de seguir las normas de sintaxis de YAML.","title":"\u00bfC\u00f3mo puedo personalizar estas acciones?"},{"location":"acciones_explicadas/#donde-puedo-ver-la-documentacion-generada","text":"La documentaci\u00f3n generada se encuentra en la carpeta site/ , que puede ser desplegada en GitHub Pages o cualquier servidor est\u00e1tico. \u00a1Gracias por usar estas acciones automatizadas! Si necesitas m\u00e1s ayuda, no dudes en consultar con el equipo o revisar la configuraci\u00f3n de los workflows.","title":"\u00bfD\u00f3nde puedo ver la documentaci\u00f3n generada?"},{"location":"api/","text":"API Reference \u00b6 CAVEDataset \u00b6 Bases: Dataset Dataset class for loading Hyperspectral images dataset (CAVE). Source code in src/capo_tools/datasets/CAVE/dataset.py class CAVEDataset(Dataset): \"\"\" Dataset class for loading Hyperspectral images dataset (CAVE). \"\"\" def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample __getitem__(idx) \u00b6 Get a sample from the dataset at the specified index. Parameters: Name Type Description Default idx int Index of the sample to retrieve. required Returns: Type Description torch.Tensor: Transformed sample. Source code in src/capo_tools/datasets/CAVE/dataset.py def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample __init__(root_dir, patch_size, transform=None, download=False, mode='train') \u00b6 Initializes the dataset by loading the data. Parameters: Name Type Description Default root_dir str Root directory where the dataset is stored. required patch_size tuple Size of the patch to be extracted from the images. required transform callable Optional transform to be applied on the samples. None download bool If True, downloads the dataset from the internet if it's not already downloaded. False mode str Mode of the dataset ('train', 'valid', 'test'.). 'train' Source code in src/capo_tools/datasets/CAVE/dataset.py def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') __len__() \u00b6 Get the total number of images in the dataset. Returns: Name Type Description int Total number of images. Source code in src/capo_tools/datasets/CAVE/dataset.py def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) DownSampling_LossChannels \u00b6 Bases: Module Crop the given image at a random location. Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py class DownSampling_LossChannels(torch.nn.Module): \"\"\" Crop the given image at a random location. \"\"\" def __init__(self, loss_ch=None): super().__init__() self.loss_ch = loss_ch or list(range(1, 31, 2)) def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y} forward(y) \u00b6 Parameters: Name Type Description Default y Tensor Image to be downsampled channel-wise. [ch, height, width] required Returns: Type Description Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y} extract_random_patch(image, size) \u00b6 Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. Source code in src/capo_tools/datasets/CAVE/utils/extract_random_patch.py def extract_random_patch(image, size): \"\"\" Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. \"\"\" # Get image dimensions img_height, img_width = image.shape[:2] patch_height, patch_width = size # Choose random starting coordinates for the patch start_row = np.random.randint(0, img_height - patch_height + 1) start_col = np.random.randint(0, img_width - patch_width + 1) # Extract the patch patch = image[start_row:start_row + patch_height, start_col:start_col + patch_width] return patch ETS2Dataset \u00b6 Bases: Dataset Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2Dataset(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None): super(ETS2Dataset, self).__init__() self.data_path = data_path self.image_type = image_type self.is_train = is_train self.data = get_data(self.data_path) self.indexes = indexes if indexes is not None else list(range(len(self.data))) self.transform = transform if transform is not None else ToTensor() def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes) __getitem__(item) \u00b6 Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata Source code in src/capo_tools/datasets/ETS2/dataset.py def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample __len__() \u00b6 Get the number of frames in the dataset Source code in src/capo_tools/datasets/ETS2/dataset.py def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes) ETS2DatasetVideo \u00b6 Bases: Dataset Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2DatasetVideo(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0): super(ETS2DatasetVideo, self).__init__() self.data_path = data_path self.is_train = is_train self.data_indexes = indexes self.data = get_data(data_path) self.transform = transform self.maxDepth = max_depth def __getitem__(self, item): sequence_start_index = self.data_indexes[item] # TODO: parametrize number of frames in sequence sequence_end_index = sequence_start_index + 10 data_rows = self.data.iloc[sequence_start_index:sequence_end_index, :] files = [os.path.join(self.data_path, x) for x in (data_rows['session'] + \"/\" + data_rows['capture']).tolist()] x = [] y = [] metadata = [] for index, file in enumerate(files): file_path = f\"{file}.jpg\" image = Image.open(file_path) depth_file = read_depth_file(f\"{file}.depth.raw\") header = depth_file['header'] depth = -depth_file['data'] depth_shape = (header['height'], header['width'], 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file} sample = self.transform(sample) x.append(sample['image']) y.append(sample['depth']) data_row = data_rows.iloc[index] metadata.append({\"path\": file_path, \"session\": data_row['session'], \"capture\": data_row['capture']}) x = torch.stack((x)) y = torch.stack((y)) return x, y, metadata def __len__(self): return len(self.data_indexes) ToTensor \u00b6 Bases: object Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors Source code in src/capo_tools/datasets/ETS2/dataset.py class ToTensor(object): \"\"\" Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors \"\"\" def __call__(self, sample): image, depth = sample['image'], sample['depth'] image = pil_to_tensor(image).float() depth = torch.from_numpy(depth).float().permute(2, 0, 1) metadata = sample['metadata'] frame = sample['frame'] return {'image': image, 'depth': depth, 'frame': frame, 'metadata': metadata} ETS2DepthFile \u00b6 Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFile: def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() def _read_depth_file(self): data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self.header = ETS2DepthFileHeader(data) # TODO: review, find a better way to do this, # self.is_real_depth = (self.header.bit_depth == 16) if self.eager_load: self._read_data(data) del data def _read_depth_data(self, file_data): data_bytes = self.header.bit_depth // 8 denorm = pow(2, 24) - 1 # TODO: Review, this hardcoded 28 should be self.header.offset? format = '<%sU' % int((self.header.size - 26) / data_bytes) self.data = np.array(rawutil.unpack(format, file_data[self.header.offset:])) # self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) self.data = self.data / denorm # data = normalize(data) def _read_realdepth_data(self, file_data): data_bytes = self.header.bit_depth // 8 # TODO: Review, make sure this is the same, as np.from_buffer is much much faster than rawutil.unpack # TODO: Review, this hardcoded 28 should be self.header.offset? # format = '<%se' % int((self.header.size - 28) / data_bytes) # self.data = -np.array(rawutil.unpack(format, file_data[self.header.offset:])) self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) # NaN handling data_nans = np.count_nonzero(np.isnan(self.data)) if data_nans > 0: warnings.warn(f\"{os.path.join(self.base, f'{self.file_name}{self.ext}')}: There are {data_nans} NaN values in depth data, transforming them to zeros\") self.data[np.isnan(self.data)] = 0 def _read_data(self, data): if self.is_real_depth: self._read_realdepth_data(data) else: self._read_depth_data(data) def get_data(self): if self.data is None: data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self._read_data(data) del data return self.data def size(self): return self.header.width, self.header.height __init__(file, far_value=10000, eager_load=True) \u00b6 ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() ETS2DepthFileHeader \u00b6 Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFileHeader: def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) def _read_header(self, data): if len(data) == 3525146: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"offset\": struct.unpack('<l', data[22:26])[0], \"bit_depth\": 24 } else: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"bit_depth\": struct.unpack('<h', data[22:24])[0], \"offset\": struct.unpack('<l', data[24:28])[0] } self.__dict__.update(header) del header def __str__(self): return (f\"magic: {self.magic}, \" f\"size: {self.size}, \" f\"widht: {self.width}, \" f\"height: {self.height}, \" f\"minimum value: {self.min_val}, \" f\"maximum value: {self.max_val}, \" f\"bit depth: {self.bit_depth}, \" f\"offset: {self.offset}\") __init__(data) \u00b6 ETS2 Datset depth file header Args: data (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) ffp3d(tensor, kernel) \u00b6 Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Parameters: Name Type Description Default tensor Tensor Input tensor. required kernel Tensor Convolution kernel. required Returns: Type Description torch.Tensor: Convolved tensor. Source code in src/capo_tools/pt_functions/ffts.py def ffp3d(tensor, kernel): \"\"\" Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Args: tensor (torch.Tensor): Input tensor. kernel (torch.Tensor): Convolution kernel. Returns: torch.Tensor: Convolved tensor. \"\"\" c_org, h_org, w_org = tensor.size() kc, kh, kw = kernel.size() pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the input tensor tensor_pad = F.pad(tensor, (pad_w, pad_w, pad_h, pad_h, pad_c, pad_c)) c, h, w = tensor_pad.size() # Compute FFT of kernel and input tensor kernel_fft = psf2otf3d(kernel, tensor_pad.size()) tensor_fft = torch.fft.fftn(tensor_pad, s=(c, h, w)) # Compute inverse FFT and extract the valid part k_conv_t = torch.fft.ifftn(kernel_fft * tensor_fft)[pad_c:pad_c + c_org, pad_h:pad_h + h_org, pad_w:pad_w + w_org] return k_conv_t psf2otf3d(kernel, input_shape, n=1) \u00b6 Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Parameters: Name Type Description Default kernel Tensor The PSF kernel. required input_shape tuple Shape of the input tensor (channels, height, width). required n int Number of samples. Defaults to 1. 1 Returns: Type Description torch.Tensor: OTF of the kernel. Source code in src/capo_tools/pt_functions/ffts.py def psf2otf3d(kernel, input_shape, n=1): \"\"\" Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Args: kernel (torch.Tensor): The PSF kernel. input_shape (tuple): Shape of the input tensor (channels, height, width). n (int): Number of samples. Defaults to 1. Returns: torch.Tensor: OTF of the kernel. \"\"\" kc, kh, kw = kernel.size() c, h, w = input_shape pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the kernel and roll it kernel_pad = F.pad(kernel, (0, w - kw, 0, h - kh, 0, c - kc), \"constant\", 0) kernel_pad_roll = torch.roll(kernel_pad, shifts=(-pad_c, -pad_h, -pad_w), dims=(0, 1, 2)) # Compute the OTF using FFT kernel_otf = torch.fft.fftn(kernel_pad_roll, s=(c, h, w)) return kernel_otf","title":"API"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset","text":"Bases: Dataset Dataset class for loading Hyperspectral images dataset (CAVE). Source code in src/capo_tools/datasets/CAVE/dataset.py class CAVEDataset(Dataset): \"\"\" Dataset class for loading Hyperspectral images dataset (CAVE). \"\"\" def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.') def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images) def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample","title":"CAVEDataset"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__getitem__","text":"Get a sample from the dataset at the specified index. Parameters: Name Type Description Default idx int Index of the sample to retrieve. required Returns: Type Description torch.Tensor: Transformed sample. Source code in src/capo_tools/datasets/CAVE/dataset.py def __getitem__(self, idx): \"\"\" Get a sample from the dataset at the specified index. Args: idx (int): Index of the sample to retrieve. Returns: torch.Tensor: Transformed sample. \"\"\" if torch.is_tensor(idx): idx = idx.tolist() idx = idx % len(self.images) image = self.images[idx] image: np.ndarray = extract_random_patch(image, self.patch_size) image = image.astype(np.float32) if self.transform: sample = self.transform(image) else: sample = transforms.ToTensor()(image) return sample","title":"__getitem__"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__init__","text":"Initializes the dataset by loading the data. Parameters: Name Type Description Default root_dir str Root directory where the dataset is stored. required patch_size tuple Size of the patch to be extracted from the images. required transform callable Optional transform to be applied on the samples. None download bool If True, downloads the dataset from the internet if it's not already downloaded. False mode str Mode of the dataset ('train', 'valid', 'test'.). 'train' Source code in src/capo_tools/datasets/CAVE/dataset.py def __init__(self, root_dir: str, patch_size: tuple, transform=None, download=False, mode='train'): \"\"\" Initializes the dataset by loading the data. Args: root_dir (str): Root directory where the dataset is stored. patch_size (tuple): Size of the patch to be extracted from the images. transform (callable, optional): Optional transform to be applied on the samples. download (bool, optional): If True, downloads the dataset from the internet if it's not already downloaded. mode (str, optional): Mode of the dataset ('train', 'valid', 'test'.). \"\"\" if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) if download: if not os.path.exists(root_dir): print('Downloading CAVE dataset:') download_CAVE(path_to_save=root_dir) else: print('Downloading and restoring CAVE dataset:') shutil.rmtree(root_dir) download_CAVE(path_to_save=root_dir) self.root_dir = os.path.join(root_dir, mode) self.patch_size = patch_size self.transform = transform self.images: list = [] images_paths: list = sorted(os.listdir(self.root_dir)) for path in images_paths: numpy_image: np.ndarray = np.load(os.path.join(self.root_dir, path)) padded_image: np.ndarray = np.pad(numpy_image, (self.patch_size, self.patch_size, (0, 0)), 'constant', constant_values=0) self.images.append(padded_image) print('CAVE dataset loaded.')","title":"__init__"},{"location":"api/#capo_tools.datasets.CAVE.dataset.CAVEDataset.__len__","text":"Get the total number of images in the dataset. Returns: Name Type Description int Total number of images. Source code in src/capo_tools/datasets/CAVE/dataset.py def __len__(self): \"\"\" Get the total number of images in the dataset. Returns: int: Total number of images. \"\"\" return len(self.images)","title":"__len__"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels","text":"Bases: Module Crop the given image at a random location. Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py class DownSampling_LossChannels(torch.nn.Module): \"\"\" Crop the given image at a random location. \"\"\" def __init__(self, loss_ch=None): super().__init__() self.loss_ch = loss_ch or list(range(1, 31, 2)) def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y}","title":"DownSampling_LossChannels"},{"location":"api/#capo_tools.datasets.CAVE.utils.downsampling.DownSampling_LossChannels.forward","text":"Parameters: Name Type Description Default y Tensor Image to be downsampled channel-wise. [ch, height, width] required Returns: Type Description Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} Source code in src/capo_tools/datasets/CAVE/utils/downsampling.py def forward(self, y): \"\"\" Args: y (Tensor): Image to be downsampled channel-wise. [ch, height, width] Returns: Dict of Tensors: {'x': Downsampled image with lost channels set to 0, 'y': y} \"\"\" x = y.clone() x[self.loss_ch, ...] = 0 return {'x': x, 'y': y}","title":"forward"},{"location":"api/#capo_tools.datasets.CAVE.utils.extract_random_patch.extract_random_patch","text":"Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. Source code in src/capo_tools/datasets/CAVE/utils/extract_random_patch.py def extract_random_patch(image, size): \"\"\" Extracts a random patch of size 'size' from the input image. Zero padding is applied if the patch exceeds the image boundaries. Parameters: - image: NumPy array representing the input image. - size: Tuple (height, width) specifying the size of the patch. Returns: - patch: NumPy array representing the extracted patch. \"\"\" # Get image dimensions img_height, img_width = image.shape[:2] patch_height, patch_width = size # Choose random starting coordinates for the patch start_row = np.random.randint(0, img_height - patch_height + 1) start_col = np.random.randint(0, img_width - patch_width + 1) # Extract the patch patch = image[start_row:start_row + patch_height, start_col:start_col + patch_width] return patch","title":"extract_random_patch"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset","text":"Bases: Dataset Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2Dataset(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, single frame The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, data_path, indexes, image_type: str = 'bmp', is_train: bool = False, transform=None): super(ETS2Dataset, self).__init__() self.data_path = data_path self.image_type = image_type self.is_train = is_train self.data = get_data(self.data_path) self.indexes = indexes if indexes is not None else list(range(len(self.data))) self.transform = transform if transform is not None else ToTensor() def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes)","title":"ETS2Dataset"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset.__getitem__","text":"Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata Source code in src/capo_tools/datasets/ETS2/dataset.py def __getitem__(self, item): \"\"\" Get a single frame from the dataset Returns a tuple with the image and the depth map and a dictionary with the metadata \"\"\" index = self.indexes[item] row = self.data.iloc[index] file_path = os.path.join(self.data_path, row['session'], row['capture']) image = Image.open(f\"{file_path}.{self.image_type}\") depth_file = read_depth_file(f\"{file_path}.depth.raw\") header = depth_file.header depth = depth_file.get_data() depth_shape = (header.height, header.width, 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file_path, 'metadata': row} if self.transform: sample = self.transform(sample) return sample","title":"__getitem__"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2Dataset.__len__","text":"Get the number of frames in the dataset Source code in src/capo_tools/datasets/ETS2/dataset.py def __len__(self): \"\"\" Get the number of frames in the dataset \"\"\" return len(self.indexes)","title":"__len__"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ETS2DatasetVideo","text":"Bases: Dataset Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 Source code in src/capo_tools/datasets/ETS2/dataset.py class ETS2DatasetVideo(Dataset): \"\"\" Pytorch Dataset for ETS2 dataset, video sequence The ETS2 Dataset, Synthetic Data from Video Games for Monocular Depth Estimation https://link.springer.com/chapter/10.1007/978-3-031-36616-1_30 \"\"\" def __init__(self, indexes, data_path, is_train=False, transform=None, max_depth: float = 80.0): super(ETS2DatasetVideo, self).__init__() self.data_path = data_path self.is_train = is_train self.data_indexes = indexes self.data = get_data(data_path) self.transform = transform self.maxDepth = max_depth def __getitem__(self, item): sequence_start_index = self.data_indexes[item] # TODO: parametrize number of frames in sequence sequence_end_index = sequence_start_index + 10 data_rows = self.data.iloc[sequence_start_index:sequence_end_index, :] files = [os.path.join(self.data_path, x) for x in (data_rows['session'] + \"/\" + data_rows['capture']).tolist()] x = [] y = [] metadata = [] for index, file in enumerate(files): file_path = f\"{file}.jpg\" image = Image.open(file_path) depth_file = read_depth_file(f\"{file}.depth.raw\") header = depth_file['header'] depth = -depth_file['data'] depth_shape = (header['height'], header['width'], 1) depth = np.reshape(depth, depth_shape) sample = {'image': image, 'depth': depth, 'frame': file} sample = self.transform(sample) x.append(sample['image']) y.append(sample['depth']) data_row = data_rows.iloc[index] metadata.append({\"path\": file_path, \"session\": data_row['session'], \"capture\": data_row['capture']}) x = torch.stack((x)) y = torch.stack((y)) return x, y, metadata def __len__(self): return len(self.data_indexes)","title":"ETS2DatasetVideo"},{"location":"api/#capo_tools.datasets.ETS2.dataset.ToTensor","text":"Bases: object Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors Source code in src/capo_tools/datasets/ETS2/dataset.py class ToTensor(object): \"\"\" Convert ETS2 sample to Tensors Returns a dictionary with two elements, image and depth, both as Tensors This class doesn't perform any transformation on the data, it just converts the data to Tensors \"\"\" def __call__(self, sample): image, depth = sample['image'], sample['depth'] image = pil_to_tensor(image).float() depth = torch.from_numpy(depth).float().permute(2, 0, 1) metadata = sample['metadata'] frame = sample['frame'] return {'image': image, 'depth': depth, 'frame': frame, 'metadata': metadata}","title":"ToTensor"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile","text":"Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFile: def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file() def _read_depth_file(self): data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self.header = ETS2DepthFileHeader(data) # TODO: review, find a better way to do this, # self.is_real_depth = (self.header.bit_depth == 16) if self.eager_load: self._read_data(data) del data def _read_depth_data(self, file_data): data_bytes = self.header.bit_depth // 8 denorm = pow(2, 24) - 1 # TODO: Review, this hardcoded 28 should be self.header.offset? format = '<%sU' % int((self.header.size - 26) / data_bytes) self.data = np.array(rawutil.unpack(format, file_data[self.header.offset:])) # self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) self.data = self.data / denorm # data = normalize(data) def _read_realdepth_data(self, file_data): data_bytes = self.header.bit_depth // 8 # TODO: Review, make sure this is the same, as np.from_buffer is much much faster than rawutil.unpack # TODO: Review, this hardcoded 28 should be self.header.offset? # format = '<%se' % int((self.header.size - 28) / data_bytes) # self.data = -np.array(rawutil.unpack(format, file_data[self.header.offset:])) self.data = -np.frombuffer(file_data[self.header.offset:], dtype=np.float16).astype(np.float32) # NaN handling data_nans = np.count_nonzero(np.isnan(self.data)) if data_nans > 0: warnings.warn(f\"{os.path.join(self.base, f'{self.file_name}{self.ext}')}: There are {data_nans} NaN values in depth data, transforming them to zeros\") self.data[np.isnan(self.data)] = 0 def _read_data(self, data): if self.is_real_depth: self._read_realdepth_data(data) else: self._read_depth_data(data) def get_data(self): if self.data is None: data = np.fromfile(os.path.join(self.base, f\"{self.file_name}{self.ext}\"), dtype='byte') self._read_data(data) del data return self.data def size(self): return self.header.width, self.header.height","title":"ETS2DepthFile"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFile.__init__","text":"ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, file: str, far_value: float = 10000, eager_load: bool = True): \"\"\" ETS2 dataset depth file reader Args: file (): far_value (): eager_load (): \"\"\" # File must exist assert os.path.exists(file) self.base, _file_name = os.path.split(file) self.file_name, self.ext = os.path.splitext(_file_name) # File name assertions assert self.ext == \".raw\" assert len(self.file_name.split('.')) > 1 assert self.file_name.split('.')[1] == 'depth' self.bit_depth = None self.data = None self.eager_load = eager_load self.far_value = far_value self._read_depth_file()","title":"__init__"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader","text":"Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py class ETS2DepthFileHeader: def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data) def _read_header(self, data): if len(data) == 3525146: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"offset\": struct.unpack('<l', data[22:26])[0], \"bit_depth\": 24 } else: header = { \"magic\": bytes(struct.unpack('bb', data[0:2])).decode('utf-8'), \"size\": struct.unpack('<l', data[2:6])[0], \"width\": struct.unpack('<l', data[6:10])[0], \"height\": struct.unpack('<l', data[10:14])[0], \"min_val\": struct.unpack('<f', data[14:18])[0], \"max_val\": struct.unpack('<f', data[18:22])[0], \"bit_depth\": struct.unpack('<h', data[22:24])[0], \"offset\": struct.unpack('<l', data[24:28])[0] } self.__dict__.update(header) del header def __str__(self): return (f\"magic: {self.magic}, \" f\"size: {self.size}, \" f\"widht: {self.width}, \" f\"height: {self.height}, \" f\"minimum value: {self.min_val}, \" f\"maximum value: {self.max_val}, \" f\"bit depth: {self.bit_depth}, \" f\"offset: {self.offset}\")","title":"ETS2DepthFileHeader"},{"location":"api/#capo_tools.datasets.ETS2.ets2_tools.depth_file.ETS2DepthFileHeader.__init__","text":"ETS2 Datset depth file header Args: data (): Source code in src/capo_tools/datasets/ETS2/ets2_tools/depth_file.py def __init__(self, data): \"\"\" ETS2 Datset depth file header Args: data (): \"\"\" self.magic: str = None self.size: int = None self.width: int = None self.height: int = None self.min_val: int = None self.max_val: int = None self.offset: int = None self.bit_depth: int = None self._read_header(data)","title":"__init__"},{"location":"api/#capo_tools.pt_functions.ffts.ffp3d","text":"Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Parameters: Name Type Description Default tensor Tensor Input tensor. required kernel Tensor Convolution kernel. required Returns: Type Description torch.Tensor: Convolved tensor. Source code in src/capo_tools/pt_functions/ffts.py def ffp3d(tensor, kernel): \"\"\" Perform 3D Fast Fourier Transform and Convolution in the frequency domain. Args: tensor (torch.Tensor): Input tensor. kernel (torch.Tensor): Convolution kernel. Returns: torch.Tensor: Convolved tensor. \"\"\" c_org, h_org, w_org = tensor.size() kc, kh, kw = kernel.size() pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the input tensor tensor_pad = F.pad(tensor, (pad_w, pad_w, pad_h, pad_h, pad_c, pad_c)) c, h, w = tensor_pad.size() # Compute FFT of kernel and input tensor kernel_fft = psf2otf3d(kernel, tensor_pad.size()) tensor_fft = torch.fft.fftn(tensor_pad, s=(c, h, w)) # Compute inverse FFT and extract the valid part k_conv_t = torch.fft.ifftn(kernel_fft * tensor_fft)[pad_c:pad_c + c_org, pad_h:pad_h + h_org, pad_w:pad_w + w_org] return k_conv_t","title":"ffp3d"},{"location":"api/#capo_tools.pt_functions.ffts.psf2otf3d","text":"Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Parameters: Name Type Description Default kernel Tensor The PSF kernel. required input_shape tuple Shape of the input tensor (channels, height, width). required n int Number of samples. Defaults to 1. 1 Returns: Type Description torch.Tensor: OTF of the kernel. Source code in src/capo_tools/pt_functions/ffts.py def psf2otf3d(kernel, input_shape, n=1): \"\"\" Convert PSF (Point Spread Function) to OTF (Optical Transfer Function) in the frequency domain. Args: kernel (torch.Tensor): The PSF kernel. input_shape (tuple): Shape of the input tensor (channels, height, width). n (int): Number of samples. Defaults to 1. Returns: torch.Tensor: OTF of the kernel. \"\"\" kc, kh, kw = kernel.size() c, h, w = input_shape pad_c, pad_h, pad_w = kc // 2, kh // 2, kw // 2 # Pad the kernel and roll it kernel_pad = F.pad(kernel, (0, w - kw, 0, h - kh, 0, c - kc), \"constant\", 0) kernel_pad_roll = torch.roll(kernel_pad, shifts=(-pad_c, -pad_h, -pad_w), dims=(0, 1, 2)) # Compute the OTF using FFT kernel_otf = torch.fft.fftn(kernel_pad_roll, s=(c, h, w)) return kernel_otf","title":"psf2otf3d"},{"location":"manual_de_usuario/","text":"Manual de Usuario: Uso de Acciones de Automatizaci\u00f3n en el Proyecto \u00b6 Este manual est\u00e1 dise\u00f1ado para guiar a los desarrolladores en el uso de las acciones de automatizaci\u00f3n configuradas en el proyecto. Aqu\u00ed se explica qu\u00e9 hacer para a\u00f1adir funcionalidades al proyecto, gestionar nuevas librer\u00edas y activar los workflows correctamente. 1. Acciones Automatizadas en GitHub Actions \u00b6 El proyecto cuenta con tres acciones automatizadas para garantizar la calidad, la documentaci\u00f3n y el empaquetado del proyecto. Estas acciones est\u00e1n explicadas m\u00e1s detalladamente en la secci\u00f3n \"Acciones explicadas\". 1.1 Python Package \u00b6 Prop\u00f3sito : Instala dependencias, ejecuta an\u00e1lisis de calidad con flake8 y corre los tests. Trigger : Push a main o creaci\u00f3n de un Pull Request. 1.2 Generate and Publish Documentation \u00b6 Prop\u00f3sito : Genera documentaci\u00f3n actualizada combinando docstrings del c\u00f3digo en src/ con documentaci\u00f3n manual en docs/ . Trigger : Push a main . 1.3 Upload Python Package \u00b6 Prop\u00f3sito : Crea un paquete Python y lo sube a Test PyPI con el nombre del release. Trigger : Publicaci\u00f3n de un release en GitHub. 2. Pipeline de Trabajo para los Desarrolladores \u00b6 Paso 1: Clonar el Repositorio \u00b6 Clona el repositorio en tu m\u00e1quina local: bash git clone https://github.com/capo-urjc/python-tools.git Accede al directorio del proyecto: bash cd proyecto Paso 2: Desarrollar la Funcionalidad \u00b6 Crea una nueva rama para trabajar en tu funcionalidad: bash git checkout -b feature/nueva-funcionalidad Realiza las siguientes tareas: 2.1 Incluir tu c\u00f3digo : A\u00f1ade el c\u00f3digo necesario en los archivos correspondientes del proyecto. 2.2 Desarrollar los tests unitarios : Escribe tests para validar la funcionalidad en la carpeta de tests. 2.3 Documentar el c\u00f3digo : A\u00f1ade docstrings en formato Google y, si es necesario, actualiza la documentaci\u00f3n manual en la carpeta docs/ . Debes a\u00f1adir tus archivos en docs/api.md en este formato \"::: src.capo_tools.ejemplo\" Paso 3: Verificar el Funcionamiento Correcto \u00b6 Aseg\u00farate de que el c\u00f3digo pasa las acciones: Python package: Revisar el feedback de flake8 para la calidad del c\u00f3digo y el feedback de pytest con los tests unitarios. Modificar las restricciones de lint con flake8 si es necesario seg\u00fan tus requisitos, al igual que a la hora de pasar los tests con pypi. Upload python package: Revisar que el nombre de versi\u00f3n del tag del realease es correcto con el formato \"vX.X.X\". Verificar que el paquete se ha construido correctamente con twine. Por \u00faltimo, comprobar que se ha subido correctamente a TestPypi. Generate and publish documentation: Comprobar en https://capo-urjc.github.io/python-tools/ que se ha subido la documentaci\u00f3n correctamente. La documentaci\u00f3n del c\u00f3digo est\u00e1 en el apartado API. Para ello tiene que estar en docs/api.md vuestros archivos a\u00f1adidos. Si has a\u00f1adido nuevas dependencias: Inst\u00e1lalas y agr\u00e9galas de forma manual al archivo pyproject.toml en la secci\u00f3n [tool.pdm.dev-dependencies]: bash pip install nombre-libreria Paso 4: Crear el Pull Request \u00b6 Sube tus cambios a tu rama remota: bash git push origin feature/nueva-funcionalidad Abre un Pull Request en GitHub contra la rama main . Verifica que las acciones automatizadas en GitHub Actions se ejecuten correctamente: La acci\u00f3n Python Package debe pasar sin errores. La acci\u00f3n Generate and Publish Documentation debe generar la documentaci\u00f3n correctamente. 3. Consideraciones Adicionales \u00b6 Errores en las Acciones \u00b6 Si alguna acci\u00f3n falla, revisa los logs en la pesta\u00f1a Actions de GitHub para identificar el problema. Soluciona los errores y haz un nuevo push. Credenciales para Test PyPI \u00b6 Aseg\u00farate de que las credenciales est\u00e1n configuradas en los secrets del repositorio si necesitas publicar un paquete. Resumen del Pipeline \u00b6 Clonar el repositorio : bash git clone https://github.com/usuario/proyecto.git cd proyecto Desarrollar la funcionalidad : Crear una rama: bash git checkout -b feature/nueva-funcionalidad Incluir el c\u00f3digo. A\u00f1adir tests unitarios. Documentar el c\u00f3digo con docstrings y actualizar docs/ si es necesario. Verificar el funcionamiento correcto : Ejecutar flake8: bash flake8 src/ Ejecutar los tests: bash pytest Generar documentaci\u00f3n local: bash mkdocs serve Crear el Pull Request : Subir los cambios: bash git push origin feature/nueva-funcionalidad Abrir un Pull Request en GitHub. Confirmar que las acciones de GitHub se ejecuten correctamente : Validar que todas las acciones pasan sin errores.","title":"Manual de usuario"},{"location":"manual_de_usuario/#manual-de-usuario-uso-de-acciones-de-automatizacion-en-el-proyecto","text":"Este manual est\u00e1 dise\u00f1ado para guiar a los desarrolladores en el uso de las acciones de automatizaci\u00f3n configuradas en el proyecto. Aqu\u00ed se explica qu\u00e9 hacer para a\u00f1adir funcionalidades al proyecto, gestionar nuevas librer\u00edas y activar los workflows correctamente.","title":"Manual de Usuario: Uso de Acciones de Automatizaci\u00f3n en el Proyecto"},{"location":"manual_de_usuario/#1-acciones-automatizadas-en-github-actions","text":"El proyecto cuenta con tres acciones automatizadas para garantizar la calidad, la documentaci\u00f3n y el empaquetado del proyecto. Estas acciones est\u00e1n explicadas m\u00e1s detalladamente en la secci\u00f3n \"Acciones explicadas\".","title":"1. Acciones Automatizadas en GitHub Actions"},{"location":"manual_de_usuario/#11-python-package","text":"Prop\u00f3sito : Instala dependencias, ejecuta an\u00e1lisis de calidad con flake8 y corre los tests. Trigger : Push a main o creaci\u00f3n de un Pull Request.","title":"1.1 Python Package"},{"location":"manual_de_usuario/#12-generate-and-publish-documentation","text":"Prop\u00f3sito : Genera documentaci\u00f3n actualizada combinando docstrings del c\u00f3digo en src/ con documentaci\u00f3n manual en docs/ . Trigger : Push a main .","title":"1.2 Generate and Publish Documentation"},{"location":"manual_de_usuario/#13-upload-python-package","text":"Prop\u00f3sito : Crea un paquete Python y lo sube a Test PyPI con el nombre del release. Trigger : Publicaci\u00f3n de un release en GitHub.","title":"1.3 Upload Python Package"},{"location":"manual_de_usuario/#2-pipeline-de-trabajo-para-los-desarrolladores","text":"","title":"2. Pipeline de Trabajo para los Desarrolladores"},{"location":"manual_de_usuario/#paso-1-clonar-el-repositorio","text":"Clona el repositorio en tu m\u00e1quina local: bash git clone https://github.com/capo-urjc/python-tools.git Accede al directorio del proyecto: bash cd proyecto","title":"Paso 1: Clonar el Repositorio"},{"location":"manual_de_usuario/#paso-2-desarrollar-la-funcionalidad","text":"Crea una nueva rama para trabajar en tu funcionalidad: bash git checkout -b feature/nueva-funcionalidad Realiza las siguientes tareas: 2.1 Incluir tu c\u00f3digo : A\u00f1ade el c\u00f3digo necesario en los archivos correspondientes del proyecto. 2.2 Desarrollar los tests unitarios : Escribe tests para validar la funcionalidad en la carpeta de tests. 2.3 Documentar el c\u00f3digo : A\u00f1ade docstrings en formato Google y, si es necesario, actualiza la documentaci\u00f3n manual en la carpeta docs/ . Debes a\u00f1adir tus archivos en docs/api.md en este formato \"::: src.capo_tools.ejemplo\"","title":"Paso 2: Desarrollar la Funcionalidad"},{"location":"manual_de_usuario/#paso-3-verificar-el-funcionamiento-correcto","text":"Aseg\u00farate de que el c\u00f3digo pasa las acciones: Python package: Revisar el feedback de flake8 para la calidad del c\u00f3digo y el feedback de pytest con los tests unitarios. Modificar las restricciones de lint con flake8 si es necesario seg\u00fan tus requisitos, al igual que a la hora de pasar los tests con pypi. Upload python package: Revisar que el nombre de versi\u00f3n del tag del realease es correcto con el formato \"vX.X.X\". Verificar que el paquete se ha construido correctamente con twine. Por \u00faltimo, comprobar que se ha subido correctamente a TestPypi. Generate and publish documentation: Comprobar en https://capo-urjc.github.io/python-tools/ que se ha subido la documentaci\u00f3n correctamente. La documentaci\u00f3n del c\u00f3digo est\u00e1 en el apartado API. Para ello tiene que estar en docs/api.md vuestros archivos a\u00f1adidos. Si has a\u00f1adido nuevas dependencias: Inst\u00e1lalas y agr\u00e9galas de forma manual al archivo pyproject.toml en la secci\u00f3n [tool.pdm.dev-dependencies]: bash pip install nombre-libreria","title":"Paso 3: Verificar el Funcionamiento Correcto"},{"location":"manual_de_usuario/#paso-4-crear-el-pull-request","text":"Sube tus cambios a tu rama remota: bash git push origin feature/nueva-funcionalidad Abre un Pull Request en GitHub contra la rama main . Verifica que las acciones automatizadas en GitHub Actions se ejecuten correctamente: La acci\u00f3n Python Package debe pasar sin errores. La acci\u00f3n Generate and Publish Documentation debe generar la documentaci\u00f3n correctamente.","title":"Paso 4: Crear el Pull Request"},{"location":"manual_de_usuario/#3-consideraciones-adicionales","text":"","title":"3. Consideraciones Adicionales"},{"location":"manual_de_usuario/#errores-en-las-acciones","text":"Si alguna acci\u00f3n falla, revisa los logs en la pesta\u00f1a Actions de GitHub para identificar el problema. Soluciona los errores y haz un nuevo push.","title":"Errores en las Acciones"},{"location":"manual_de_usuario/#credenciales-para-test-pypi","text":"Aseg\u00farate de que las credenciales est\u00e1n configuradas en los secrets del repositorio si necesitas publicar un paquete.","title":"Credenciales para Test PyPI"},{"location":"manual_de_usuario/#resumen-del-pipeline","text":"Clonar el repositorio : bash git clone https://github.com/usuario/proyecto.git cd proyecto Desarrollar la funcionalidad : Crear una rama: bash git checkout -b feature/nueva-funcionalidad Incluir el c\u00f3digo. A\u00f1adir tests unitarios. Documentar el c\u00f3digo con docstrings y actualizar docs/ si es necesario. Verificar el funcionamiento correcto : Ejecutar flake8: bash flake8 src/ Ejecutar los tests: bash pytest Generar documentaci\u00f3n local: bash mkdocs serve Crear el Pull Request : Subir los cambios: bash git push origin feature/nueva-funcionalidad Abrir un Pull Request en GitHub. Confirmar que las acciones de GitHub se ejecuten correctamente : Validar que todas las acciones pasan sin errores.","title":"Resumen del Pipeline"}]}